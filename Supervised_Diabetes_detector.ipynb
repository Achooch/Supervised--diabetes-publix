{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Supervised -Diabetes detector",
      "provenance": [],
      "mount_file_id": "114Us9OU6oOK9SMMS7RKMm1U-qJd0LNcE",
      "authorship_tag": "ABX9TyPA8kUntMqxgW1xwvazpVZe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Achooch/Supervised--diabetes-publix/blob/master/Supervised_Diabetes_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZETofk73VCH",
        "colab_type": "text"
      },
      "source": [
        "Supervised learning regression probability array as result in test function \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oy6S4fSgZDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "509JHGWf7R7l",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8d1ca25e-3cbe-4819-c047-1e39a32406ff"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-727fc2bf-cee5-4cc4-849e-64671bdf4905\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-727fc2bf-cee5-4cc4-849e-64671bdf4905\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving diabetes.csv to diabetes (3).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-19N-VchbHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "a41a43e9-2aae-4e58-ef66-ae564df6265a"
      },
      "source": [
        "df = pd.read_csv('diabetes.csv')\n",
        "df.head(7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "5            5      116             74  ...                     0.201   30        0\n",
              "6            3       78             50  ...                     0.248   26        1\n",
              "\n",
              "[7 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3lbuyPrhu9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ed73d61-b59f-4d08-db2c-6b1b21a0543b"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH8T0scEh9Ma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9816aa1-3731-4e5d-ce25-b0736ef05423"
      },
      "source": [
        "#check and remove duplicates\n",
        "df.drop_duplicates(inplace = True)\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J2ghe77iMXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "cd7c8ff5-2442-48e6-da55-924e82724681"
      },
      "source": [
        "#display number of missing data\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PGcCf3YiWij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e7786da4-9938-4d80-f3b5-8a60129cc093"
      },
      "source": [
        "#convert data to array\n",
        "dataset = df.values\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQOY6HSdid6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get all rows for inputs (X = first 8 rows, y = last row)\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y26B-VyPi3FK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "2a8bd19e-436e-4076-9742-9b9fe071f9db"
      },
      "source": [
        "#preprocess the data (scale)\n",
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_FpdYGxjGLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the data train-val-test (test size = split %)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size = 0.2, random_state = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VQ1S50ZjaoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build the model\n",
        "model = Sequential([\n",
        "    Dense(12, activation = 'relu', input_shape = (8,)),\n",
        "    Dense(15, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtcXz3rXkKPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    optimizer = 'sgd',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR40k5NVkaRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa8b80b7-f0d9-4a87-8db0-4fa1db413504"
      },
      "source": [
        "#train the model\n",
        "hist = model.fit(X_train, y_train, batch_size=64, epochs= 1000, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 491 samples, validate on 123 samples\n",
            "Epoch 1/1000\n",
            "491/491 [==============================] - 0s 172us/step - loss: 0.6945 - accuracy: 0.4420 - val_loss: 0.6905 - val_accuracy: 0.5854\n",
            "Epoch 2/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6880 - accuracy: 0.6415 - val_loss: 0.6844 - val_accuracy: 0.6667\n",
            "Epoch 3/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6827 - accuracy: 0.6619 - val_loss: 0.6792 - val_accuracy: 0.6748\n",
            "Epoch 4/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6781 - accuracy: 0.6456 - val_loss: 0.6748 - val_accuracy: 0.6585\n",
            "Epoch 5/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6743 - accuracy: 0.6456 - val_loss: 0.6712 - val_accuracy: 0.6585\n",
            "Epoch 6/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6713 - accuracy: 0.6497 - val_loss: 0.6679 - val_accuracy: 0.6504\n",
            "Epoch 7/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6683 - accuracy: 0.6477 - val_loss: 0.6651 - val_accuracy: 0.6504\n",
            "Epoch 8/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6658 - accuracy: 0.6477 - val_loss: 0.6628 - val_accuracy: 0.6504\n",
            "Epoch 9/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6638 - accuracy: 0.6477 - val_loss: 0.6609 - val_accuracy: 0.6504\n",
            "Epoch 10/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6620 - accuracy: 0.6477 - val_loss: 0.6592 - val_accuracy: 0.6504\n",
            "Epoch 11/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6606 - accuracy: 0.6477 - val_loss: 0.6578 - val_accuracy: 0.6504\n",
            "Epoch 12/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6593 - accuracy: 0.6477 - val_loss: 0.6565 - val_accuracy: 0.6504\n",
            "Epoch 13/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6582 - accuracy: 0.6477 - val_loss: 0.6553 - val_accuracy: 0.6504\n",
            "Epoch 14/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6571 - accuracy: 0.6477 - val_loss: 0.6543 - val_accuracy: 0.6504\n",
            "Epoch 15/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6562 - accuracy: 0.6477 - val_loss: 0.6534 - val_accuracy: 0.6504\n",
            "Epoch 16/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6554 - accuracy: 0.6477 - val_loss: 0.6526 - val_accuracy: 0.6504\n",
            "Epoch 17/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6547 - accuracy: 0.6477 - val_loss: 0.6519 - val_accuracy: 0.6504\n",
            "Epoch 18/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6541 - accuracy: 0.6477 - val_loss: 0.6513 - val_accuracy: 0.6504\n",
            "Epoch 19/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6535 - accuracy: 0.6477 - val_loss: 0.6506 - val_accuracy: 0.6504\n",
            "Epoch 20/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6528 - accuracy: 0.6477 - val_loss: 0.6499 - val_accuracy: 0.6504\n",
            "Epoch 21/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6521 - accuracy: 0.6477 - val_loss: 0.6494 - val_accuracy: 0.6504\n",
            "Epoch 22/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6516 - accuracy: 0.6477 - val_loss: 0.6488 - val_accuracy: 0.6504\n",
            "Epoch 23/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6512 - accuracy: 0.6477 - val_loss: 0.6483 - val_accuracy: 0.6504\n",
            "Epoch 24/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6505 - accuracy: 0.6477 - val_loss: 0.6478 - val_accuracy: 0.6504\n",
            "Epoch 25/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6500 - accuracy: 0.6477 - val_loss: 0.6474 - val_accuracy: 0.6504\n",
            "Epoch 26/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6496 - accuracy: 0.6477 - val_loss: 0.6470 - val_accuracy: 0.6504\n",
            "Epoch 27/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.6491 - accuracy: 0.6477 - val_loss: 0.6465 - val_accuracy: 0.6504\n",
            "Epoch 28/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6486 - accuracy: 0.6477 - val_loss: 0.6461 - val_accuracy: 0.6504\n",
            "Epoch 29/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6482 - accuracy: 0.6477 - val_loss: 0.6457 - val_accuracy: 0.6504\n",
            "Epoch 30/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6477 - accuracy: 0.6477 - val_loss: 0.6452 - val_accuracy: 0.6504\n",
            "Epoch 31/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6473 - accuracy: 0.6477 - val_loss: 0.6448 - val_accuracy: 0.6504\n",
            "Epoch 32/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6468 - accuracy: 0.6477 - val_loss: 0.6444 - val_accuracy: 0.6504\n",
            "Epoch 33/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6464 - accuracy: 0.6477 - val_loss: 0.6441 - val_accuracy: 0.6504\n",
            "Epoch 34/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6460 - accuracy: 0.6477 - val_loss: 0.6437 - val_accuracy: 0.6504\n",
            "Epoch 35/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6455 - accuracy: 0.6477 - val_loss: 0.6433 - val_accuracy: 0.6504\n",
            "Epoch 36/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6451 - accuracy: 0.6477 - val_loss: 0.6430 - val_accuracy: 0.6504\n",
            "Epoch 37/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6447 - accuracy: 0.6477 - val_loss: 0.6426 - val_accuracy: 0.6504\n",
            "Epoch 38/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6442 - accuracy: 0.6477 - val_loss: 0.6423 - val_accuracy: 0.6504\n",
            "Epoch 39/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6438 - accuracy: 0.6477 - val_loss: 0.6419 - val_accuracy: 0.6504\n",
            "Epoch 40/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6433 - accuracy: 0.6477 - val_loss: 0.6416 - val_accuracy: 0.6504\n",
            "Epoch 41/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6430 - accuracy: 0.6477 - val_loss: 0.6412 - val_accuracy: 0.6504\n",
            "Epoch 42/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6426 - accuracy: 0.6477 - val_loss: 0.6408 - val_accuracy: 0.6504\n",
            "Epoch 43/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6421 - accuracy: 0.6477 - val_loss: 0.6405 - val_accuracy: 0.6504\n",
            "Epoch 44/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6417 - accuracy: 0.6477 - val_loss: 0.6401 - val_accuracy: 0.6504\n",
            "Epoch 45/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6414 - accuracy: 0.6477 - val_loss: 0.6398 - val_accuracy: 0.6504\n",
            "Epoch 46/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6409 - accuracy: 0.6477 - val_loss: 0.6394 - val_accuracy: 0.6504\n",
            "Epoch 47/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6405 - accuracy: 0.6477 - val_loss: 0.6391 - val_accuracy: 0.6504\n",
            "Epoch 48/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6401 - accuracy: 0.6477 - val_loss: 0.6387 - val_accuracy: 0.6504\n",
            "Epoch 49/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.6397 - accuracy: 0.6477 - val_loss: 0.6384 - val_accuracy: 0.6504\n",
            "Epoch 50/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6392 - accuracy: 0.6477 - val_loss: 0.6380 - val_accuracy: 0.6504\n",
            "Epoch 51/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6388 - accuracy: 0.6477 - val_loss: 0.6377 - val_accuracy: 0.6504\n",
            "Epoch 52/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6384 - accuracy: 0.6477 - val_loss: 0.6374 - val_accuracy: 0.6504\n",
            "Epoch 53/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6381 - accuracy: 0.6477 - val_loss: 0.6370 - val_accuracy: 0.6504\n",
            "Epoch 54/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6378 - accuracy: 0.6477 - val_loss: 0.6367 - val_accuracy: 0.6504\n",
            "Epoch 55/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6373 - accuracy: 0.6477 - val_loss: 0.6363 - val_accuracy: 0.6504\n",
            "Epoch 56/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6368 - accuracy: 0.6477 - val_loss: 0.6360 - val_accuracy: 0.6504\n",
            "Epoch 57/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6365 - accuracy: 0.6477 - val_loss: 0.6357 - val_accuracy: 0.6504\n",
            "Epoch 58/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6361 - accuracy: 0.6477 - val_loss: 0.6353 - val_accuracy: 0.6504\n",
            "Epoch 59/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6356 - accuracy: 0.6477 - val_loss: 0.6350 - val_accuracy: 0.6504\n",
            "Epoch 60/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6352 - accuracy: 0.6477 - val_loss: 0.6346 - val_accuracy: 0.6504\n",
            "Epoch 61/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6349 - accuracy: 0.6477 - val_loss: 0.6343 - val_accuracy: 0.6504\n",
            "Epoch 62/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6345 - accuracy: 0.6477 - val_loss: 0.6339 - val_accuracy: 0.6504\n",
            "Epoch 63/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6341 - accuracy: 0.6477 - val_loss: 0.6336 - val_accuracy: 0.6504\n",
            "Epoch 64/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6336 - accuracy: 0.6477 - val_loss: 0.6333 - val_accuracy: 0.6504\n",
            "Epoch 65/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6333 - accuracy: 0.6477 - val_loss: 0.6329 - val_accuracy: 0.6504\n",
            "Epoch 66/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6329 - accuracy: 0.6477 - val_loss: 0.6326 - val_accuracy: 0.6504\n",
            "Epoch 67/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6324 - accuracy: 0.6477 - val_loss: 0.6322 - val_accuracy: 0.6504\n",
            "Epoch 68/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6321 - accuracy: 0.6477 - val_loss: 0.6319 - val_accuracy: 0.6504\n",
            "Epoch 69/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6316 - accuracy: 0.6477 - val_loss: 0.6315 - val_accuracy: 0.6504\n",
            "Epoch 70/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6313 - accuracy: 0.6477 - val_loss: 0.6312 - val_accuracy: 0.6504\n",
            "Epoch 71/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6308 - accuracy: 0.6477 - val_loss: 0.6309 - val_accuracy: 0.6504\n",
            "Epoch 72/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6304 - accuracy: 0.6477 - val_loss: 0.6305 - val_accuracy: 0.6504\n",
            "Epoch 73/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6300 - accuracy: 0.6477 - val_loss: 0.6301 - val_accuracy: 0.6504\n",
            "Epoch 74/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6295 - accuracy: 0.6477 - val_loss: 0.6298 - val_accuracy: 0.6504\n",
            "Epoch 75/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6291 - accuracy: 0.6477 - val_loss: 0.6295 - val_accuracy: 0.6504\n",
            "Epoch 76/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6286 - accuracy: 0.6477 - val_loss: 0.6291 - val_accuracy: 0.6504\n",
            "Epoch 77/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6283 - accuracy: 0.6477 - val_loss: 0.6288 - val_accuracy: 0.6504\n",
            "Epoch 78/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6280 - accuracy: 0.6477 - val_loss: 0.6285 - val_accuracy: 0.6504\n",
            "Epoch 79/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6274 - accuracy: 0.6477 - val_loss: 0.6282 - val_accuracy: 0.6504\n",
            "Epoch 80/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6271 - accuracy: 0.6477 - val_loss: 0.6278 - val_accuracy: 0.6504\n",
            "Epoch 81/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6266 - accuracy: 0.6477 - val_loss: 0.6274 - val_accuracy: 0.6504\n",
            "Epoch 82/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6262 - accuracy: 0.6477 - val_loss: 0.6271 - val_accuracy: 0.6504\n",
            "Epoch 83/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6258 - accuracy: 0.6477 - val_loss: 0.6267 - val_accuracy: 0.6504\n",
            "Epoch 84/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6253 - accuracy: 0.6477 - val_loss: 0.6264 - val_accuracy: 0.6504\n",
            "Epoch 85/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6249 - accuracy: 0.6477 - val_loss: 0.6260 - val_accuracy: 0.6504\n",
            "Epoch 86/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6246 - accuracy: 0.6477 - val_loss: 0.6257 - val_accuracy: 0.6504\n",
            "Epoch 87/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6241 - accuracy: 0.6477 - val_loss: 0.6253 - val_accuracy: 0.6504\n",
            "Epoch 88/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6237 - accuracy: 0.6477 - val_loss: 0.6250 - val_accuracy: 0.6504\n",
            "Epoch 89/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6233 - accuracy: 0.6477 - val_loss: 0.6246 - val_accuracy: 0.6504\n",
            "Epoch 90/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6228 - accuracy: 0.6477 - val_loss: 0.6243 - val_accuracy: 0.6504\n",
            "Epoch 91/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6224 - accuracy: 0.6477 - val_loss: 0.6239 - val_accuracy: 0.6504\n",
            "Epoch 92/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6220 - accuracy: 0.6477 - val_loss: 0.6236 - val_accuracy: 0.6504\n",
            "Epoch 93/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6216 - accuracy: 0.6477 - val_loss: 0.6232 - val_accuracy: 0.6504\n",
            "Epoch 94/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6212 - accuracy: 0.6477 - val_loss: 0.6228 - val_accuracy: 0.6504\n",
            "Epoch 95/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6207 - accuracy: 0.6477 - val_loss: 0.6225 - val_accuracy: 0.6504\n",
            "Epoch 96/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6203 - accuracy: 0.6477 - val_loss: 0.6222 - val_accuracy: 0.6504\n",
            "Epoch 97/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6198 - accuracy: 0.6477 - val_loss: 0.6217 - val_accuracy: 0.6504\n",
            "Epoch 98/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6194 - accuracy: 0.6477 - val_loss: 0.6214 - val_accuracy: 0.6504\n",
            "Epoch 99/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6191 - accuracy: 0.6477 - val_loss: 0.6211 - val_accuracy: 0.6504\n",
            "Epoch 100/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6185 - accuracy: 0.6477 - val_loss: 0.6207 - val_accuracy: 0.6504\n",
            "Epoch 101/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6180 - accuracy: 0.6497 - val_loss: 0.6203 - val_accuracy: 0.6504\n",
            "Epoch 102/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6176 - accuracy: 0.6477 - val_loss: 0.6200 - val_accuracy: 0.6504\n",
            "Epoch 103/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6171 - accuracy: 0.6497 - val_loss: 0.6196 - val_accuracy: 0.6504\n",
            "Epoch 104/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6167 - accuracy: 0.6497 - val_loss: 0.6193 - val_accuracy: 0.6504\n",
            "Epoch 105/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6163 - accuracy: 0.6497 - val_loss: 0.6189 - val_accuracy: 0.6504\n",
            "Epoch 106/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6159 - accuracy: 0.6497 - val_loss: 0.6185 - val_accuracy: 0.6504\n",
            "Epoch 107/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6155 - accuracy: 0.6497 - val_loss: 0.6182 - val_accuracy: 0.6504\n",
            "Epoch 108/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6149 - accuracy: 0.6517 - val_loss: 0.6178 - val_accuracy: 0.6504\n",
            "Epoch 109/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6145 - accuracy: 0.6538 - val_loss: 0.6174 - val_accuracy: 0.6504\n",
            "Epoch 110/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6140 - accuracy: 0.6538 - val_loss: 0.6171 - val_accuracy: 0.6504\n",
            "Epoch 111/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6136 - accuracy: 0.6538 - val_loss: 0.6167 - val_accuracy: 0.6504\n",
            "Epoch 112/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6131 - accuracy: 0.6538 - val_loss: 0.6163 - val_accuracy: 0.6504\n",
            "Epoch 113/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6127 - accuracy: 0.6538 - val_loss: 0.6159 - val_accuracy: 0.6504\n",
            "Epoch 114/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6121 - accuracy: 0.6558 - val_loss: 0.6155 - val_accuracy: 0.6504\n",
            "Epoch 115/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6117 - accuracy: 0.6558 - val_loss: 0.6151 - val_accuracy: 0.6504\n",
            "Epoch 116/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6114 - accuracy: 0.6558 - val_loss: 0.6148 - val_accuracy: 0.6585\n",
            "Epoch 117/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.6110 - accuracy: 0.6578 - val_loss: 0.6144 - val_accuracy: 0.6585\n",
            "Epoch 118/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6104 - accuracy: 0.6578 - val_loss: 0.6140 - val_accuracy: 0.6585\n",
            "Epoch 119/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6100 - accuracy: 0.6578 - val_loss: 0.6136 - val_accuracy: 0.6585\n",
            "Epoch 120/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6094 - accuracy: 0.6578 - val_loss: 0.6132 - val_accuracy: 0.6585\n",
            "Epoch 121/1000\n",
            "491/491 [==============================] - 0s 23us/step - loss: 0.6090 - accuracy: 0.6558 - val_loss: 0.6128 - val_accuracy: 0.6585\n",
            "Epoch 122/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6085 - accuracy: 0.6578 - val_loss: 0.6124 - val_accuracy: 0.6585\n",
            "Epoch 123/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6080 - accuracy: 0.6558 - val_loss: 0.6120 - val_accuracy: 0.6585\n",
            "Epoch 124/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6076 - accuracy: 0.6578 - val_loss: 0.6117 - val_accuracy: 0.6585\n",
            "Epoch 125/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6071 - accuracy: 0.6619 - val_loss: 0.6113 - val_accuracy: 0.6585\n",
            "Epoch 126/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6067 - accuracy: 0.6599 - val_loss: 0.6109 - val_accuracy: 0.6585\n",
            "Epoch 127/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6062 - accuracy: 0.6619 - val_loss: 0.6105 - val_accuracy: 0.6585\n",
            "Epoch 128/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6056 - accuracy: 0.6640 - val_loss: 0.6101 - val_accuracy: 0.6585\n",
            "Epoch 129/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6053 - accuracy: 0.6619 - val_loss: 0.6097 - val_accuracy: 0.6585\n",
            "Epoch 130/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6047 - accuracy: 0.6619 - val_loss: 0.6093 - val_accuracy: 0.6667\n",
            "Epoch 131/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6042 - accuracy: 0.6619 - val_loss: 0.6089 - val_accuracy: 0.6667\n",
            "Epoch 132/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6037 - accuracy: 0.6640 - val_loss: 0.6085 - val_accuracy: 0.6667\n",
            "Epoch 133/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.6033 - accuracy: 0.6640 - val_loss: 0.6081 - val_accuracy: 0.6667\n",
            "Epoch 134/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6027 - accuracy: 0.6660 - val_loss: 0.6077 - val_accuracy: 0.6667\n",
            "Epoch 135/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6023 - accuracy: 0.6640 - val_loss: 0.6073 - val_accuracy: 0.6667\n",
            "Epoch 136/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6019 - accuracy: 0.6640 - val_loss: 0.6069 - val_accuracy: 0.6667\n",
            "Epoch 137/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6013 - accuracy: 0.6660 - val_loss: 0.6065 - val_accuracy: 0.6667\n",
            "Epoch 138/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.6011 - accuracy: 0.6660 - val_loss: 0.6061 - val_accuracy: 0.6667\n",
            "Epoch 139/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6003 - accuracy: 0.6680 - val_loss: 0.6057 - val_accuracy: 0.6667\n",
            "Epoch 140/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6000 - accuracy: 0.6660 - val_loss: 0.6053 - val_accuracy: 0.6585\n",
            "Epoch 141/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5994 - accuracy: 0.6680 - val_loss: 0.6050 - val_accuracy: 0.6667\n",
            "Epoch 142/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5988 - accuracy: 0.6721 - val_loss: 0.6046 - val_accuracy: 0.6667\n",
            "Epoch 143/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5983 - accuracy: 0.6721 - val_loss: 0.6041 - val_accuracy: 0.6667\n",
            "Epoch 144/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5977 - accuracy: 0.6721 - val_loss: 0.6037 - val_accuracy: 0.6585\n",
            "Epoch 145/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5973 - accuracy: 0.6741 - val_loss: 0.6033 - val_accuracy: 0.6585\n",
            "Epoch 146/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5967 - accuracy: 0.6741 - val_loss: 0.6029 - val_accuracy: 0.6585\n",
            "Epoch 147/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5964 - accuracy: 0.6741 - val_loss: 0.6024 - val_accuracy: 0.6585\n",
            "Epoch 148/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5958 - accuracy: 0.6762 - val_loss: 0.6020 - val_accuracy: 0.6585\n",
            "Epoch 149/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5952 - accuracy: 0.6782 - val_loss: 0.6016 - val_accuracy: 0.6585\n",
            "Epoch 150/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5948 - accuracy: 0.6762 - val_loss: 0.6012 - val_accuracy: 0.6585\n",
            "Epoch 151/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5943 - accuracy: 0.6802 - val_loss: 0.6008 - val_accuracy: 0.6585\n",
            "Epoch 152/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5937 - accuracy: 0.6802 - val_loss: 0.6004 - val_accuracy: 0.6585\n",
            "Epoch 153/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5931 - accuracy: 0.6802 - val_loss: 0.5999 - val_accuracy: 0.6667\n",
            "Epoch 154/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5926 - accuracy: 0.6802 - val_loss: 0.5996 - val_accuracy: 0.6667\n",
            "Epoch 155/1000\n",
            "491/491 [==============================] - 0s 23us/step - loss: 0.5920 - accuracy: 0.6843 - val_loss: 0.5991 - val_accuracy: 0.6667\n",
            "Epoch 156/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5916 - accuracy: 0.6843 - val_loss: 0.5986 - val_accuracy: 0.6667\n",
            "Epoch 157/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5910 - accuracy: 0.6843 - val_loss: 0.5982 - val_accuracy: 0.6667\n",
            "Epoch 158/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5905 - accuracy: 0.6904 - val_loss: 0.5978 - val_accuracy: 0.6667\n",
            "Epoch 159/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5901 - accuracy: 0.6864 - val_loss: 0.5974 - val_accuracy: 0.6504\n",
            "Epoch 160/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5894 - accuracy: 0.6884 - val_loss: 0.5969 - val_accuracy: 0.6504\n",
            "Epoch 161/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5888 - accuracy: 0.6925 - val_loss: 0.5965 - val_accuracy: 0.6504\n",
            "Epoch 162/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5884 - accuracy: 0.6945 - val_loss: 0.5960 - val_accuracy: 0.6504\n",
            "Epoch 163/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5878 - accuracy: 0.6925 - val_loss: 0.5956 - val_accuracy: 0.6585\n",
            "Epoch 164/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5874 - accuracy: 0.6925 - val_loss: 0.5952 - val_accuracy: 0.6585\n",
            "Epoch 165/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5868 - accuracy: 0.6945 - val_loss: 0.5948 - val_accuracy: 0.6585\n",
            "Epoch 166/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5864 - accuracy: 0.6965 - val_loss: 0.5943 - val_accuracy: 0.6585\n",
            "Epoch 167/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5857 - accuracy: 0.6965 - val_loss: 0.5939 - val_accuracy: 0.6585\n",
            "Epoch 168/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5851 - accuracy: 0.6945 - val_loss: 0.5935 - val_accuracy: 0.6585\n",
            "Epoch 169/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5847 - accuracy: 0.6965 - val_loss: 0.5931 - val_accuracy: 0.6667\n",
            "Epoch 170/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5842 - accuracy: 0.6986 - val_loss: 0.5926 - val_accuracy: 0.6667\n",
            "Epoch 171/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5838 - accuracy: 0.6986 - val_loss: 0.5921 - val_accuracy: 0.6667\n",
            "Epoch 172/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5831 - accuracy: 0.6965 - val_loss: 0.5917 - val_accuracy: 0.6667\n",
            "Epoch 173/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5827 - accuracy: 0.6965 - val_loss: 0.5913 - val_accuracy: 0.6667\n",
            "Epoch 174/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5819 - accuracy: 0.6965 - val_loss: 0.5909 - val_accuracy: 0.6748\n",
            "Epoch 175/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5814 - accuracy: 0.7026 - val_loss: 0.5904 - val_accuracy: 0.6748\n",
            "Epoch 176/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5810 - accuracy: 0.7067 - val_loss: 0.5899 - val_accuracy: 0.6748\n",
            "Epoch 177/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5804 - accuracy: 0.7026 - val_loss: 0.5895 - val_accuracy: 0.6748\n",
            "Epoch 178/1000\n",
            "491/491 [==============================] - 0s 23us/step - loss: 0.5799 - accuracy: 0.7067 - val_loss: 0.5891 - val_accuracy: 0.6748\n",
            "Epoch 179/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5794 - accuracy: 0.7108 - val_loss: 0.5887 - val_accuracy: 0.6748\n",
            "Epoch 180/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5788 - accuracy: 0.7067 - val_loss: 0.5883 - val_accuracy: 0.6748\n",
            "Epoch 181/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5782 - accuracy: 0.7088 - val_loss: 0.5879 - val_accuracy: 0.6748\n",
            "Epoch 182/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5777 - accuracy: 0.7088 - val_loss: 0.5875 - val_accuracy: 0.6748\n",
            "Epoch 183/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5773 - accuracy: 0.7067 - val_loss: 0.5871 - val_accuracy: 0.6829\n",
            "Epoch 184/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5769 - accuracy: 0.7088 - val_loss: 0.5867 - val_accuracy: 0.6829\n",
            "Epoch 185/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5762 - accuracy: 0.7108 - val_loss: 0.5862 - val_accuracy: 0.6829\n",
            "Epoch 186/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5755 - accuracy: 0.7108 - val_loss: 0.5858 - val_accuracy: 0.6829\n",
            "Epoch 187/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5752 - accuracy: 0.7108 - val_loss: 0.5854 - val_accuracy: 0.6829\n",
            "Epoch 188/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5747 - accuracy: 0.7088 - val_loss: 0.5849 - val_accuracy: 0.6829\n",
            "Epoch 189/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5741 - accuracy: 0.7108 - val_loss: 0.5845 - val_accuracy: 0.6748\n",
            "Epoch 190/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5737 - accuracy: 0.7108 - val_loss: 0.5840 - val_accuracy: 0.6748\n",
            "Epoch 191/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5729 - accuracy: 0.7088 - val_loss: 0.5836 - val_accuracy: 0.6748\n",
            "Epoch 192/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5724 - accuracy: 0.7108 - val_loss: 0.5833 - val_accuracy: 0.6748\n",
            "Epoch 193/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5720 - accuracy: 0.7108 - val_loss: 0.5828 - val_accuracy: 0.6748\n",
            "Epoch 194/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5714 - accuracy: 0.7108 - val_loss: 0.5824 - val_accuracy: 0.6748\n",
            "Epoch 195/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5710 - accuracy: 0.7108 - val_loss: 0.5820 - val_accuracy: 0.6748\n",
            "Epoch 196/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5703 - accuracy: 0.7108 - val_loss: 0.5817 - val_accuracy: 0.6748\n",
            "Epoch 197/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5699 - accuracy: 0.7088 - val_loss: 0.5812 - val_accuracy: 0.6748\n",
            "Epoch 198/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5694 - accuracy: 0.7088 - val_loss: 0.5807 - val_accuracy: 0.6748\n",
            "Epoch 199/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5689 - accuracy: 0.7128 - val_loss: 0.5803 - val_accuracy: 0.6748\n",
            "Epoch 200/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5684 - accuracy: 0.7108 - val_loss: 0.5800 - val_accuracy: 0.6911\n",
            "Epoch 201/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5678 - accuracy: 0.7088 - val_loss: 0.5796 - val_accuracy: 0.6911\n",
            "Epoch 202/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5672 - accuracy: 0.7128 - val_loss: 0.5792 - val_accuracy: 0.6911\n",
            "Epoch 203/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5668 - accuracy: 0.7128 - val_loss: 0.5788 - val_accuracy: 0.6992\n",
            "Epoch 204/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5663 - accuracy: 0.7128 - val_loss: 0.5784 - val_accuracy: 0.6992\n",
            "Epoch 205/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5659 - accuracy: 0.7128 - val_loss: 0.5780 - val_accuracy: 0.6992\n",
            "Epoch 206/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5652 - accuracy: 0.7108 - val_loss: 0.5777 - val_accuracy: 0.6911\n",
            "Epoch 207/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5647 - accuracy: 0.7149 - val_loss: 0.5771 - val_accuracy: 0.6992\n",
            "Epoch 208/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5644 - accuracy: 0.7108 - val_loss: 0.5769 - val_accuracy: 0.6992\n",
            "Epoch 209/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5639 - accuracy: 0.7128 - val_loss: 0.5764 - val_accuracy: 0.6992\n",
            "Epoch 210/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5634 - accuracy: 0.7149 - val_loss: 0.5759 - val_accuracy: 0.7073\n",
            "Epoch 211/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5628 - accuracy: 0.7128 - val_loss: 0.5755 - val_accuracy: 0.6992\n",
            "Epoch 212/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5621 - accuracy: 0.7128 - val_loss: 0.5751 - val_accuracy: 0.6992\n",
            "Epoch 213/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5616 - accuracy: 0.7149 - val_loss: 0.5748 - val_accuracy: 0.6992\n",
            "Epoch 214/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5613 - accuracy: 0.7128 - val_loss: 0.5744 - val_accuracy: 0.6992\n",
            "Epoch 215/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5607 - accuracy: 0.7128 - val_loss: 0.5740 - val_accuracy: 0.6992\n",
            "Epoch 216/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5601 - accuracy: 0.7149 - val_loss: 0.5736 - val_accuracy: 0.7073\n",
            "Epoch 217/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5597 - accuracy: 0.7169 - val_loss: 0.5731 - val_accuracy: 0.7073\n",
            "Epoch 218/1000\n",
            "491/491 [==============================] - 0s 23us/step - loss: 0.5592 - accuracy: 0.7149 - val_loss: 0.5728 - val_accuracy: 0.6992\n",
            "Epoch 219/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5586 - accuracy: 0.7149 - val_loss: 0.5724 - val_accuracy: 0.6992\n",
            "Epoch 220/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5581 - accuracy: 0.7128 - val_loss: 0.5721 - val_accuracy: 0.6992\n",
            "Epoch 221/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5580 - accuracy: 0.7149 - val_loss: 0.5717 - val_accuracy: 0.6992\n",
            "Epoch 222/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5572 - accuracy: 0.7169 - val_loss: 0.5713 - val_accuracy: 0.6992\n",
            "Epoch 223/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5566 - accuracy: 0.7149 - val_loss: 0.5709 - val_accuracy: 0.6992\n",
            "Epoch 224/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5563 - accuracy: 0.7169 - val_loss: 0.5704 - val_accuracy: 0.6992\n",
            "Epoch 225/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5556 - accuracy: 0.7128 - val_loss: 0.5702 - val_accuracy: 0.6992\n",
            "Epoch 226/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5551 - accuracy: 0.7210 - val_loss: 0.5697 - val_accuracy: 0.6992\n",
            "Epoch 227/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5548 - accuracy: 0.7169 - val_loss: 0.5694 - val_accuracy: 0.6911\n",
            "Epoch 228/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5544 - accuracy: 0.7210 - val_loss: 0.5690 - val_accuracy: 0.6992\n",
            "Epoch 229/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5537 - accuracy: 0.7210 - val_loss: 0.5687 - val_accuracy: 0.7073\n",
            "Epoch 230/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5533 - accuracy: 0.7189 - val_loss: 0.5682 - val_accuracy: 0.7073\n",
            "Epoch 231/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5527 - accuracy: 0.7149 - val_loss: 0.5680 - val_accuracy: 0.7073\n",
            "Epoch 232/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5524 - accuracy: 0.7189 - val_loss: 0.5676 - val_accuracy: 0.7073\n",
            "Epoch 233/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5517 - accuracy: 0.7210 - val_loss: 0.5672 - val_accuracy: 0.7073\n",
            "Epoch 234/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5512 - accuracy: 0.7210 - val_loss: 0.5670 - val_accuracy: 0.7073\n",
            "Epoch 235/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5509 - accuracy: 0.7210 - val_loss: 0.5666 - val_accuracy: 0.7073\n",
            "Epoch 236/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5505 - accuracy: 0.7169 - val_loss: 0.5663 - val_accuracy: 0.7073\n",
            "Epoch 237/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5498 - accuracy: 0.7210 - val_loss: 0.5660 - val_accuracy: 0.7073\n",
            "Epoch 238/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5494 - accuracy: 0.7189 - val_loss: 0.5657 - val_accuracy: 0.7073\n",
            "Epoch 239/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5489 - accuracy: 0.7210 - val_loss: 0.5652 - val_accuracy: 0.7073\n",
            "Epoch 240/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5484 - accuracy: 0.7210 - val_loss: 0.5648 - val_accuracy: 0.7073\n",
            "Epoch 241/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5481 - accuracy: 0.7169 - val_loss: 0.5645 - val_accuracy: 0.7073\n",
            "Epoch 242/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5476 - accuracy: 0.7189 - val_loss: 0.5641 - val_accuracy: 0.7073\n",
            "Epoch 243/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5470 - accuracy: 0.7210 - val_loss: 0.5636 - val_accuracy: 0.7073\n",
            "Epoch 244/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5465 - accuracy: 0.7189 - val_loss: 0.5633 - val_accuracy: 0.7073\n",
            "Epoch 245/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5461 - accuracy: 0.7230 - val_loss: 0.5629 - val_accuracy: 0.7073\n",
            "Epoch 246/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5458 - accuracy: 0.7210 - val_loss: 0.5626 - val_accuracy: 0.7073\n",
            "Epoch 247/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5451 - accuracy: 0.7189 - val_loss: 0.5623 - val_accuracy: 0.7154\n",
            "Epoch 248/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5449 - accuracy: 0.7169 - val_loss: 0.5620 - val_accuracy: 0.7073\n",
            "Epoch 249/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5441 - accuracy: 0.7088 - val_loss: 0.5616 - val_accuracy: 0.7154\n",
            "Epoch 250/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5437 - accuracy: 0.7149 - val_loss: 0.5611 - val_accuracy: 0.7154\n",
            "Epoch 251/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5435 - accuracy: 0.7210 - val_loss: 0.5610 - val_accuracy: 0.7073\n",
            "Epoch 252/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5427 - accuracy: 0.7149 - val_loss: 0.5606 - val_accuracy: 0.7073\n",
            "Epoch 253/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5422 - accuracy: 0.7189 - val_loss: 0.5603 - val_accuracy: 0.7073\n",
            "Epoch 254/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5419 - accuracy: 0.7149 - val_loss: 0.5599 - val_accuracy: 0.7073\n",
            "Epoch 255/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5414 - accuracy: 0.7169 - val_loss: 0.5596 - val_accuracy: 0.7073\n",
            "Epoch 256/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5410 - accuracy: 0.7108 - val_loss: 0.5593 - val_accuracy: 0.7073\n",
            "Epoch 257/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5403 - accuracy: 0.7108 - val_loss: 0.5589 - val_accuracy: 0.7073\n",
            "Epoch 258/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5403 - accuracy: 0.7088 - val_loss: 0.5584 - val_accuracy: 0.7154\n",
            "Epoch 259/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5397 - accuracy: 0.7210 - val_loss: 0.5582 - val_accuracy: 0.7073\n",
            "Epoch 260/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5392 - accuracy: 0.7128 - val_loss: 0.5580 - val_accuracy: 0.7073\n",
            "Epoch 261/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5388 - accuracy: 0.7128 - val_loss: 0.5577 - val_accuracy: 0.7073\n",
            "Epoch 262/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5380 - accuracy: 0.7108 - val_loss: 0.5574 - val_accuracy: 0.7073\n",
            "Epoch 263/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5378 - accuracy: 0.7149 - val_loss: 0.5571 - val_accuracy: 0.6992\n",
            "Epoch 264/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5375 - accuracy: 0.7108 - val_loss: 0.5569 - val_accuracy: 0.6992\n",
            "Epoch 265/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5371 - accuracy: 0.7128 - val_loss: 0.5565 - val_accuracy: 0.6992\n",
            "Epoch 266/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5365 - accuracy: 0.7128 - val_loss: 0.5562 - val_accuracy: 0.6992\n",
            "Epoch 267/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5359 - accuracy: 0.7128 - val_loss: 0.5558 - val_accuracy: 0.6992\n",
            "Epoch 268/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5355 - accuracy: 0.7169 - val_loss: 0.5557 - val_accuracy: 0.6992\n",
            "Epoch 269/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5352 - accuracy: 0.7108 - val_loss: 0.5553 - val_accuracy: 0.6992\n",
            "Epoch 270/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5348 - accuracy: 0.7128 - val_loss: 0.5551 - val_accuracy: 0.6992\n",
            "Epoch 271/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5346 - accuracy: 0.7128 - val_loss: 0.5546 - val_accuracy: 0.6992\n",
            "Epoch 272/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5340 - accuracy: 0.7169 - val_loss: 0.5544 - val_accuracy: 0.6992\n",
            "Epoch 273/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5335 - accuracy: 0.7169 - val_loss: 0.5540 - val_accuracy: 0.6992\n",
            "Epoch 274/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5329 - accuracy: 0.7108 - val_loss: 0.5536 - val_accuracy: 0.7073\n",
            "Epoch 275/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5327 - accuracy: 0.7128 - val_loss: 0.5533 - val_accuracy: 0.7073\n",
            "Epoch 276/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5322 - accuracy: 0.7108 - val_loss: 0.5530 - val_accuracy: 0.7073\n",
            "Epoch 277/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5316 - accuracy: 0.7169 - val_loss: 0.5528 - val_accuracy: 0.6992\n",
            "Epoch 278/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5312 - accuracy: 0.7149 - val_loss: 0.5526 - val_accuracy: 0.6992\n",
            "Epoch 279/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5309 - accuracy: 0.7128 - val_loss: 0.5523 - val_accuracy: 0.6992\n",
            "Epoch 280/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5307 - accuracy: 0.7108 - val_loss: 0.5520 - val_accuracy: 0.6992\n",
            "Epoch 281/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5299 - accuracy: 0.7149 - val_loss: 0.5517 - val_accuracy: 0.6992\n",
            "Epoch 282/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5295 - accuracy: 0.7128 - val_loss: 0.5515 - val_accuracy: 0.6992\n",
            "Epoch 283/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5295 - accuracy: 0.7149 - val_loss: 0.5514 - val_accuracy: 0.7073\n",
            "Epoch 284/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5287 - accuracy: 0.7149 - val_loss: 0.5512 - val_accuracy: 0.7154\n",
            "Epoch 285/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5284 - accuracy: 0.7189 - val_loss: 0.5507 - val_accuracy: 0.7073\n",
            "Epoch 286/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5280 - accuracy: 0.7128 - val_loss: 0.5504 - val_accuracy: 0.6992\n",
            "Epoch 287/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5277 - accuracy: 0.7128 - val_loss: 0.5502 - val_accuracy: 0.7154\n",
            "Epoch 288/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5272 - accuracy: 0.7149 - val_loss: 0.5499 - val_accuracy: 0.7073\n",
            "Epoch 289/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5268 - accuracy: 0.7149 - val_loss: 0.5497 - val_accuracy: 0.7154\n",
            "Epoch 290/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5264 - accuracy: 0.7128 - val_loss: 0.5497 - val_accuracy: 0.7154\n",
            "Epoch 291/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5262 - accuracy: 0.7189 - val_loss: 0.5498 - val_accuracy: 0.7073\n",
            "Epoch 292/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5256 - accuracy: 0.7251 - val_loss: 0.5493 - val_accuracy: 0.7073\n",
            "Epoch 293/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5256 - accuracy: 0.7210 - val_loss: 0.5489 - val_accuracy: 0.7073\n",
            "Epoch 294/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5254 - accuracy: 0.7230 - val_loss: 0.5483 - val_accuracy: 0.7154\n",
            "Epoch 295/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5246 - accuracy: 0.7169 - val_loss: 0.5482 - val_accuracy: 0.7154\n",
            "Epoch 296/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5241 - accuracy: 0.7189 - val_loss: 0.5478 - val_accuracy: 0.7154\n",
            "Epoch 297/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5241 - accuracy: 0.7169 - val_loss: 0.5476 - val_accuracy: 0.7154\n",
            "Epoch 298/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5236 - accuracy: 0.7169 - val_loss: 0.5475 - val_accuracy: 0.7154\n",
            "Epoch 299/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5231 - accuracy: 0.7189 - val_loss: 0.5473 - val_accuracy: 0.7073\n",
            "Epoch 300/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5226 - accuracy: 0.7210 - val_loss: 0.5472 - val_accuracy: 0.7073\n",
            "Epoch 301/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5220 - accuracy: 0.7251 - val_loss: 0.5468 - val_accuracy: 0.7073\n",
            "Epoch 302/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5219 - accuracy: 0.7271 - val_loss: 0.5464 - val_accuracy: 0.7154\n",
            "Epoch 303/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5214 - accuracy: 0.7251 - val_loss: 0.5463 - val_accuracy: 0.7073\n",
            "Epoch 304/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5208 - accuracy: 0.7251 - val_loss: 0.5460 - val_accuracy: 0.7073\n",
            "Epoch 305/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5206 - accuracy: 0.7251 - val_loss: 0.5456 - val_accuracy: 0.7154\n",
            "Epoch 306/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5202 - accuracy: 0.7291 - val_loss: 0.5453 - val_accuracy: 0.7154\n",
            "Epoch 307/1000\n",
            "491/491 [==============================] - 0s 23us/step - loss: 0.5199 - accuracy: 0.7251 - val_loss: 0.5449 - val_accuracy: 0.7154\n",
            "Epoch 308/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5194 - accuracy: 0.7251 - val_loss: 0.5445 - val_accuracy: 0.7154\n",
            "Epoch 309/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5194 - accuracy: 0.7251 - val_loss: 0.5444 - val_accuracy: 0.7154\n",
            "Epoch 310/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5189 - accuracy: 0.7230 - val_loss: 0.5443 - val_accuracy: 0.7154\n",
            "Epoch 311/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5186 - accuracy: 0.7230 - val_loss: 0.5440 - val_accuracy: 0.7154\n",
            "Epoch 312/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5180 - accuracy: 0.7251 - val_loss: 0.5439 - val_accuracy: 0.7073\n",
            "Epoch 313/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5177 - accuracy: 0.7291 - val_loss: 0.5438 - val_accuracy: 0.7073\n",
            "Epoch 314/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5173 - accuracy: 0.7271 - val_loss: 0.5434 - val_accuracy: 0.7073\n",
            "Epoch 315/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5169 - accuracy: 0.7312 - val_loss: 0.5431 - val_accuracy: 0.7154\n",
            "Epoch 316/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5169 - accuracy: 0.7251 - val_loss: 0.5429 - val_accuracy: 0.7154\n",
            "Epoch 317/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5161 - accuracy: 0.7291 - val_loss: 0.5426 - val_accuracy: 0.7154\n",
            "Epoch 318/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5166 - accuracy: 0.7210 - val_loss: 0.5424 - val_accuracy: 0.7154\n",
            "Epoch 319/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5155 - accuracy: 0.7291 - val_loss: 0.5422 - val_accuracy: 0.7073\n",
            "Epoch 320/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5152 - accuracy: 0.7332 - val_loss: 0.5420 - val_accuracy: 0.7154\n",
            "Epoch 321/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5147 - accuracy: 0.7291 - val_loss: 0.5420 - val_accuracy: 0.7073\n",
            "Epoch 322/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5147 - accuracy: 0.7312 - val_loss: 0.5418 - val_accuracy: 0.7073\n",
            "Epoch 323/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5140 - accuracy: 0.7291 - val_loss: 0.5415 - val_accuracy: 0.7073\n",
            "Epoch 324/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5137 - accuracy: 0.7312 - val_loss: 0.5412 - val_accuracy: 0.7073\n",
            "Epoch 325/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5133 - accuracy: 0.7312 - val_loss: 0.5410 - val_accuracy: 0.7073\n",
            "Epoch 326/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5135 - accuracy: 0.7291 - val_loss: 0.5408 - val_accuracy: 0.7073\n",
            "Epoch 327/1000\n",
            "491/491 [==============================] - 0s 23us/step - loss: 0.5126 - accuracy: 0.7291 - val_loss: 0.5407 - val_accuracy: 0.6992\n",
            "Epoch 328/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5125 - accuracy: 0.7271 - val_loss: 0.5403 - val_accuracy: 0.7154\n",
            "Epoch 329/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5124 - accuracy: 0.7312 - val_loss: 0.5404 - val_accuracy: 0.6911\n",
            "Epoch 330/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5116 - accuracy: 0.7291 - val_loss: 0.5403 - val_accuracy: 0.6911\n",
            "Epoch 331/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5124 - accuracy: 0.7271 - val_loss: 0.5401 - val_accuracy: 0.6829\n",
            "Epoch 332/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5111 - accuracy: 0.7312 - val_loss: 0.5400 - val_accuracy: 0.6829\n",
            "Epoch 333/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5108 - accuracy: 0.7332 - val_loss: 0.5397 - val_accuracy: 0.6829\n",
            "Epoch 334/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5104 - accuracy: 0.7312 - val_loss: 0.5393 - val_accuracy: 0.6911\n",
            "Epoch 335/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5098 - accuracy: 0.7291 - val_loss: 0.5393 - val_accuracy: 0.6829\n",
            "Epoch 336/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5097 - accuracy: 0.7312 - val_loss: 0.5393 - val_accuracy: 0.6829\n",
            "Epoch 337/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5099 - accuracy: 0.7291 - val_loss: 0.5394 - val_accuracy: 0.6829\n",
            "Epoch 338/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5093 - accuracy: 0.7332 - val_loss: 0.5390 - val_accuracy: 0.6829\n",
            "Epoch 339/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5087 - accuracy: 0.7373 - val_loss: 0.5385 - val_accuracy: 0.6829\n",
            "Epoch 340/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5084 - accuracy: 0.7312 - val_loss: 0.5382 - val_accuracy: 0.6829\n",
            "Epoch 341/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5081 - accuracy: 0.7312 - val_loss: 0.5380 - val_accuracy: 0.6829\n",
            "Epoch 342/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5083 - accuracy: 0.7332 - val_loss: 0.5380 - val_accuracy: 0.6829\n",
            "Epoch 343/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5075 - accuracy: 0.7312 - val_loss: 0.5376 - val_accuracy: 0.6911\n",
            "Epoch 344/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5070 - accuracy: 0.7332 - val_loss: 0.5375 - val_accuracy: 0.6829\n",
            "Epoch 345/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5068 - accuracy: 0.7312 - val_loss: 0.5374 - val_accuracy: 0.6829\n",
            "Epoch 346/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5065 - accuracy: 0.7332 - val_loss: 0.5372 - val_accuracy: 0.6829\n",
            "Epoch 347/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5063 - accuracy: 0.7352 - val_loss: 0.5373 - val_accuracy: 0.6829\n",
            "Epoch 348/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5059 - accuracy: 0.7352 - val_loss: 0.5371 - val_accuracy: 0.6829\n",
            "Epoch 349/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5058 - accuracy: 0.7332 - val_loss: 0.5369 - val_accuracy: 0.6829\n",
            "Epoch 350/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5052 - accuracy: 0.7332 - val_loss: 0.5368 - val_accuracy: 0.6829\n",
            "Epoch 351/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5052 - accuracy: 0.7393 - val_loss: 0.5366 - val_accuracy: 0.6829\n",
            "Epoch 352/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5049 - accuracy: 0.7352 - val_loss: 0.5362 - val_accuracy: 0.6829\n",
            "Epoch 353/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5043 - accuracy: 0.7352 - val_loss: 0.5362 - val_accuracy: 0.6829\n",
            "Epoch 354/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5045 - accuracy: 0.7291 - val_loss: 0.5363 - val_accuracy: 0.6748\n",
            "Epoch 355/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5039 - accuracy: 0.7352 - val_loss: 0.5357 - val_accuracy: 0.6829\n",
            "Epoch 356/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.5040 - accuracy: 0.7373 - val_loss: 0.5357 - val_accuracy: 0.6829\n",
            "Epoch 357/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5032 - accuracy: 0.7352 - val_loss: 0.5357 - val_accuracy: 0.6829\n",
            "Epoch 358/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5034 - accuracy: 0.7352 - val_loss: 0.5356 - val_accuracy: 0.6748\n",
            "Epoch 359/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5027 - accuracy: 0.7373 - val_loss: 0.5356 - val_accuracy: 0.6748\n",
            "Epoch 360/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5031 - accuracy: 0.7332 - val_loss: 0.5352 - val_accuracy: 0.6748\n",
            "Epoch 361/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5021 - accuracy: 0.7373 - val_loss: 0.5350 - val_accuracy: 0.6829\n",
            "Epoch 362/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5019 - accuracy: 0.7373 - val_loss: 0.5351 - val_accuracy: 0.6748\n",
            "Epoch 363/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5015 - accuracy: 0.7352 - val_loss: 0.5351 - val_accuracy: 0.6829\n",
            "Epoch 364/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.5017 - accuracy: 0.7373 - val_loss: 0.5349 - val_accuracy: 0.6829\n",
            "Epoch 365/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.5009 - accuracy: 0.7373 - val_loss: 0.5347 - val_accuracy: 0.6829\n",
            "Epoch 366/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.5008 - accuracy: 0.7332 - val_loss: 0.5343 - val_accuracy: 0.6829\n",
            "Epoch 367/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5006 - accuracy: 0.7413 - val_loss: 0.5345 - val_accuracy: 0.6829\n",
            "Epoch 368/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5002 - accuracy: 0.7332 - val_loss: 0.5346 - val_accuracy: 0.6829\n",
            "Epoch 369/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5000 - accuracy: 0.7373 - val_loss: 0.5344 - val_accuracy: 0.6829\n",
            "Epoch 370/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5001 - accuracy: 0.7393 - val_loss: 0.5339 - val_accuracy: 0.6829\n",
            "Epoch 371/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4994 - accuracy: 0.7352 - val_loss: 0.5336 - val_accuracy: 0.6911\n",
            "Epoch 372/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4994 - accuracy: 0.7332 - val_loss: 0.5334 - val_accuracy: 0.6911\n",
            "Epoch 373/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4993 - accuracy: 0.7413 - val_loss: 0.5333 - val_accuracy: 0.6911\n",
            "Epoch 374/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4986 - accuracy: 0.7373 - val_loss: 0.5335 - val_accuracy: 0.6829\n",
            "Epoch 375/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4982 - accuracy: 0.7352 - val_loss: 0.5331 - val_accuracy: 0.6829\n",
            "Epoch 376/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4981 - accuracy: 0.7352 - val_loss: 0.5329 - val_accuracy: 0.6911\n",
            "Epoch 377/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4979 - accuracy: 0.7352 - val_loss: 0.5328 - val_accuracy: 0.6829\n",
            "Epoch 378/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4976 - accuracy: 0.7332 - val_loss: 0.5326 - val_accuracy: 0.6911\n",
            "Epoch 379/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4972 - accuracy: 0.7332 - val_loss: 0.5326 - val_accuracy: 0.6829\n",
            "Epoch 380/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4970 - accuracy: 0.7373 - val_loss: 0.5330 - val_accuracy: 0.6829\n",
            "Epoch 381/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4970 - accuracy: 0.7312 - val_loss: 0.5325 - val_accuracy: 0.6829\n",
            "Epoch 382/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4967 - accuracy: 0.7312 - val_loss: 0.5325 - val_accuracy: 0.6829\n",
            "Epoch 383/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4964 - accuracy: 0.7393 - val_loss: 0.5321 - val_accuracy: 0.6829\n",
            "Epoch 384/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4960 - accuracy: 0.7373 - val_loss: 0.5318 - val_accuracy: 0.6911\n",
            "Epoch 385/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4960 - accuracy: 0.7352 - val_loss: 0.5317 - val_accuracy: 0.6911\n",
            "Epoch 386/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4957 - accuracy: 0.7332 - val_loss: 0.5315 - val_accuracy: 0.6992\n",
            "Epoch 387/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4953 - accuracy: 0.7332 - val_loss: 0.5314 - val_accuracy: 0.6992\n",
            "Epoch 388/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4952 - accuracy: 0.7373 - val_loss: 0.5313 - val_accuracy: 0.6992\n",
            "Epoch 389/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4951 - accuracy: 0.7413 - val_loss: 0.5314 - val_accuracy: 0.6829\n",
            "Epoch 390/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4945 - accuracy: 0.7352 - val_loss: 0.5313 - val_accuracy: 0.6829\n",
            "Epoch 391/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4947 - accuracy: 0.7332 - val_loss: 0.5312 - val_accuracy: 0.6829\n",
            "Epoch 392/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4947 - accuracy: 0.7312 - val_loss: 0.5312 - val_accuracy: 0.6829\n",
            "Epoch 393/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4939 - accuracy: 0.7332 - val_loss: 0.5308 - val_accuracy: 0.6911\n",
            "Epoch 394/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4936 - accuracy: 0.7352 - val_loss: 0.5308 - val_accuracy: 0.6829\n",
            "Epoch 395/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4935 - accuracy: 0.7352 - val_loss: 0.5311 - val_accuracy: 0.6829\n",
            "Epoch 396/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4932 - accuracy: 0.7352 - val_loss: 0.5307 - val_accuracy: 0.6829\n",
            "Epoch 397/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4929 - accuracy: 0.7373 - val_loss: 0.5304 - val_accuracy: 0.6911\n",
            "Epoch 398/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4932 - accuracy: 0.7352 - val_loss: 0.5304 - val_accuracy: 0.6911\n",
            "Epoch 399/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4923 - accuracy: 0.7373 - val_loss: 0.5306 - val_accuracy: 0.6829\n",
            "Epoch 400/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4923 - accuracy: 0.7373 - val_loss: 0.5302 - val_accuracy: 0.6911\n",
            "Epoch 401/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4922 - accuracy: 0.7352 - val_loss: 0.5302 - val_accuracy: 0.6911\n",
            "Epoch 402/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4916 - accuracy: 0.7352 - val_loss: 0.5303 - val_accuracy: 0.6829\n",
            "Epoch 403/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4916 - accuracy: 0.7373 - val_loss: 0.5302 - val_accuracy: 0.6829\n",
            "Epoch 404/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4916 - accuracy: 0.7373 - val_loss: 0.5298 - val_accuracy: 0.6911\n",
            "Epoch 405/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4910 - accuracy: 0.7373 - val_loss: 0.5297 - val_accuracy: 0.6911\n",
            "Epoch 406/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4914 - accuracy: 0.7393 - val_loss: 0.5294 - val_accuracy: 0.6911\n",
            "Epoch 407/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4907 - accuracy: 0.7352 - val_loss: 0.5293 - val_accuracy: 0.6911\n",
            "Epoch 408/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4908 - accuracy: 0.7373 - val_loss: 0.5293 - val_accuracy: 0.6911\n",
            "Epoch 409/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4903 - accuracy: 0.7373 - val_loss: 0.5292 - val_accuracy: 0.6911\n",
            "Epoch 410/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4901 - accuracy: 0.7393 - val_loss: 0.5290 - val_accuracy: 0.7154\n",
            "Epoch 411/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4906 - accuracy: 0.7373 - val_loss: 0.5290 - val_accuracy: 0.6911\n",
            "Epoch 412/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4898 - accuracy: 0.7393 - val_loss: 0.5288 - val_accuracy: 0.6992\n",
            "Epoch 413/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4896 - accuracy: 0.7434 - val_loss: 0.5290 - val_accuracy: 0.6911\n",
            "Epoch 414/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4892 - accuracy: 0.7413 - val_loss: 0.5291 - val_accuracy: 0.6911\n",
            "Epoch 415/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.4892 - accuracy: 0.7393 - val_loss: 0.5292 - val_accuracy: 0.6992\n",
            "Epoch 416/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4887 - accuracy: 0.7393 - val_loss: 0.5290 - val_accuracy: 0.6911\n",
            "Epoch 417/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4886 - accuracy: 0.7373 - val_loss: 0.5286 - val_accuracy: 0.6911\n",
            "Epoch 418/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4884 - accuracy: 0.7373 - val_loss: 0.5286 - val_accuracy: 0.6911\n",
            "Epoch 419/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4883 - accuracy: 0.7393 - val_loss: 0.5283 - val_accuracy: 0.6911\n",
            "Epoch 420/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4881 - accuracy: 0.7393 - val_loss: 0.5286 - val_accuracy: 0.6992\n",
            "Epoch 421/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4876 - accuracy: 0.7373 - val_loss: 0.5281 - val_accuracy: 0.6992\n",
            "Epoch 422/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4882 - accuracy: 0.7393 - val_loss: 0.5284 - val_accuracy: 0.6992\n",
            "Epoch 423/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4874 - accuracy: 0.7515 - val_loss: 0.5288 - val_accuracy: 0.6992\n",
            "Epoch 424/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4874 - accuracy: 0.7352 - val_loss: 0.5284 - val_accuracy: 0.7073\n",
            "Epoch 425/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4871 - accuracy: 0.7393 - val_loss: 0.5280 - val_accuracy: 0.7073\n",
            "Epoch 426/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4866 - accuracy: 0.7454 - val_loss: 0.5278 - val_accuracy: 0.7073\n",
            "Epoch 427/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4867 - accuracy: 0.7434 - val_loss: 0.5279 - val_accuracy: 0.7073\n",
            "Epoch 428/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4865 - accuracy: 0.7434 - val_loss: 0.5275 - val_accuracy: 0.7154\n",
            "Epoch 429/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4860 - accuracy: 0.7495 - val_loss: 0.5278 - val_accuracy: 0.6992\n",
            "Epoch 430/1000\n",
            "491/491 [==============================] - 0s 23us/step - loss: 0.4860 - accuracy: 0.7454 - val_loss: 0.5279 - val_accuracy: 0.6992\n",
            "Epoch 431/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4856 - accuracy: 0.7413 - val_loss: 0.5274 - val_accuracy: 0.7154\n",
            "Epoch 432/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4853 - accuracy: 0.7454 - val_loss: 0.5271 - val_accuracy: 0.7236\n",
            "Epoch 433/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4854 - accuracy: 0.7454 - val_loss: 0.5271 - val_accuracy: 0.7154\n",
            "Epoch 434/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4850 - accuracy: 0.7475 - val_loss: 0.5271 - val_accuracy: 0.7154\n",
            "Epoch 435/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4847 - accuracy: 0.7495 - val_loss: 0.5269 - val_accuracy: 0.7236\n",
            "Epoch 436/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4846 - accuracy: 0.7475 - val_loss: 0.5271 - val_accuracy: 0.7154\n",
            "Epoch 437/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4846 - accuracy: 0.7475 - val_loss: 0.5269 - val_accuracy: 0.7154\n",
            "Epoch 438/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4847 - accuracy: 0.7434 - val_loss: 0.5265 - val_accuracy: 0.7236\n",
            "Epoch 439/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4844 - accuracy: 0.7495 - val_loss: 0.5265 - val_accuracy: 0.7236\n",
            "Epoch 440/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4843 - accuracy: 0.7495 - val_loss: 0.5262 - val_accuracy: 0.7236\n",
            "Epoch 441/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4838 - accuracy: 0.7515 - val_loss: 0.5265 - val_accuracy: 0.7154\n",
            "Epoch 442/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4834 - accuracy: 0.7434 - val_loss: 0.5267 - val_accuracy: 0.7073\n",
            "Epoch 443/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4832 - accuracy: 0.7475 - val_loss: 0.5268 - val_accuracy: 0.7073\n",
            "Epoch 444/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4835 - accuracy: 0.7434 - val_loss: 0.5262 - val_accuracy: 0.7154\n",
            "Epoch 445/1000\n",
            "491/491 [==============================] - 0s 22us/step - loss: 0.4831 - accuracy: 0.7475 - val_loss: 0.5262 - val_accuracy: 0.7154\n",
            "Epoch 446/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4826 - accuracy: 0.7515 - val_loss: 0.5265 - val_accuracy: 0.7073\n",
            "Epoch 447/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4831 - accuracy: 0.7495 - val_loss: 0.5267 - val_accuracy: 0.7073\n",
            "Epoch 448/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4825 - accuracy: 0.7454 - val_loss: 0.5264 - val_accuracy: 0.7073\n",
            "Epoch 449/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4823 - accuracy: 0.7475 - val_loss: 0.5262 - val_accuracy: 0.7073\n",
            "Epoch 450/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4822 - accuracy: 0.7515 - val_loss: 0.5257 - val_accuracy: 0.7236\n",
            "Epoch 451/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4818 - accuracy: 0.7495 - val_loss: 0.5256 - val_accuracy: 0.7236\n",
            "Epoch 452/1000\n",
            "491/491 [==============================] - 0s 23us/step - loss: 0.4816 - accuracy: 0.7495 - val_loss: 0.5254 - val_accuracy: 0.7236\n",
            "Epoch 453/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4812 - accuracy: 0.7495 - val_loss: 0.5255 - val_accuracy: 0.7236\n",
            "Epoch 454/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4813 - accuracy: 0.7475 - val_loss: 0.5254 - val_accuracy: 0.7236\n",
            "Epoch 455/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4811 - accuracy: 0.7495 - val_loss: 0.5253 - val_accuracy: 0.7236\n",
            "Epoch 456/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4808 - accuracy: 0.7495 - val_loss: 0.5253 - val_accuracy: 0.7236\n",
            "Epoch 457/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4809 - accuracy: 0.7576 - val_loss: 0.5249 - val_accuracy: 0.7236\n",
            "Epoch 458/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4809 - accuracy: 0.7495 - val_loss: 0.5251 - val_accuracy: 0.7236\n",
            "Epoch 459/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4809 - accuracy: 0.7495 - val_loss: 0.5252 - val_accuracy: 0.7154\n",
            "Epoch 460/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4806 - accuracy: 0.7536 - val_loss: 0.5248 - val_accuracy: 0.7236\n",
            "Epoch 461/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4805 - accuracy: 0.7556 - val_loss: 0.5256 - val_accuracy: 0.7154\n",
            "Epoch 462/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4798 - accuracy: 0.7556 - val_loss: 0.5253 - val_accuracy: 0.7154\n",
            "Epoch 463/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4798 - accuracy: 0.7576 - val_loss: 0.5247 - val_accuracy: 0.7236\n",
            "Epoch 464/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4795 - accuracy: 0.7576 - val_loss: 0.5247 - val_accuracy: 0.7236\n",
            "Epoch 465/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4792 - accuracy: 0.7597 - val_loss: 0.5245 - val_accuracy: 0.7236\n",
            "Epoch 466/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4792 - accuracy: 0.7515 - val_loss: 0.5245 - val_accuracy: 0.7236\n",
            "Epoch 467/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4792 - accuracy: 0.7556 - val_loss: 0.5242 - val_accuracy: 0.7236\n",
            "Epoch 468/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4788 - accuracy: 0.7556 - val_loss: 0.5244 - val_accuracy: 0.7236\n",
            "Epoch 469/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4791 - accuracy: 0.7576 - val_loss: 0.5241 - val_accuracy: 0.7236\n",
            "Epoch 470/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4786 - accuracy: 0.7576 - val_loss: 0.5242 - val_accuracy: 0.7236\n",
            "Epoch 471/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4785 - accuracy: 0.7576 - val_loss: 0.5242 - val_accuracy: 0.7236\n",
            "Epoch 472/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4788 - accuracy: 0.7617 - val_loss: 0.5239 - val_accuracy: 0.7236\n",
            "Epoch 473/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4782 - accuracy: 0.7597 - val_loss: 0.5239 - val_accuracy: 0.7236\n",
            "Epoch 474/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4781 - accuracy: 0.7576 - val_loss: 0.5241 - val_accuracy: 0.7154\n",
            "Epoch 475/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4779 - accuracy: 0.7637 - val_loss: 0.5240 - val_accuracy: 0.7154\n",
            "Epoch 476/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4774 - accuracy: 0.7617 - val_loss: 0.5240 - val_accuracy: 0.7154\n",
            "Epoch 477/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4773 - accuracy: 0.7637 - val_loss: 0.5237 - val_accuracy: 0.7236\n",
            "Epoch 478/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4770 - accuracy: 0.7617 - val_loss: 0.5236 - val_accuracy: 0.7236\n",
            "Epoch 479/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4772 - accuracy: 0.7597 - val_loss: 0.5236 - val_accuracy: 0.7236\n",
            "Epoch 480/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4769 - accuracy: 0.7637 - val_loss: 0.5237 - val_accuracy: 0.7236\n",
            "Epoch 481/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4769 - accuracy: 0.7597 - val_loss: 0.5237 - val_accuracy: 0.7236\n",
            "Epoch 482/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4763 - accuracy: 0.7597 - val_loss: 0.5239 - val_accuracy: 0.7236\n",
            "Epoch 483/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4766 - accuracy: 0.7576 - val_loss: 0.5241 - val_accuracy: 0.7236\n",
            "Epoch 484/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4760 - accuracy: 0.7658 - val_loss: 0.5236 - val_accuracy: 0.7154\n",
            "Epoch 485/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4761 - accuracy: 0.7637 - val_loss: 0.5235 - val_accuracy: 0.7236\n",
            "Epoch 486/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4762 - accuracy: 0.7637 - val_loss: 0.5232 - val_accuracy: 0.7236\n",
            "Epoch 487/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4760 - accuracy: 0.7617 - val_loss: 0.5232 - val_accuracy: 0.7236\n",
            "Epoch 488/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4759 - accuracy: 0.7617 - val_loss: 0.5233 - val_accuracy: 0.7236\n",
            "Epoch 489/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4755 - accuracy: 0.7576 - val_loss: 0.5231 - val_accuracy: 0.7236\n",
            "Epoch 490/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4755 - accuracy: 0.7617 - val_loss: 0.5232 - val_accuracy: 0.7236\n",
            "Epoch 491/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4755 - accuracy: 0.7597 - val_loss: 0.5230 - val_accuracy: 0.7236\n",
            "Epoch 492/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4755 - accuracy: 0.7678 - val_loss: 0.5231 - val_accuracy: 0.7236\n",
            "Epoch 493/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4755 - accuracy: 0.7617 - val_loss: 0.5234 - val_accuracy: 0.7236\n",
            "Epoch 494/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4748 - accuracy: 0.7637 - val_loss: 0.5232 - val_accuracy: 0.7236\n",
            "Epoch 495/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4748 - accuracy: 0.7617 - val_loss: 0.5233 - val_accuracy: 0.7236\n",
            "Epoch 496/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4745 - accuracy: 0.7637 - val_loss: 0.5231 - val_accuracy: 0.7236\n",
            "Epoch 497/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4744 - accuracy: 0.7637 - val_loss: 0.5232 - val_accuracy: 0.7236\n",
            "Epoch 498/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4747 - accuracy: 0.7597 - val_loss: 0.5234 - val_accuracy: 0.7317\n",
            "Epoch 499/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4742 - accuracy: 0.7658 - val_loss: 0.5233 - val_accuracy: 0.7317\n",
            "Epoch 500/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4743 - accuracy: 0.7658 - val_loss: 0.5232 - val_accuracy: 0.7317\n",
            "Epoch 501/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4749 - accuracy: 0.7617 - val_loss: 0.5229 - val_accuracy: 0.7236\n",
            "Epoch 502/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4737 - accuracy: 0.7617 - val_loss: 0.5228 - val_accuracy: 0.7236\n",
            "Epoch 503/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4737 - accuracy: 0.7617 - val_loss: 0.5227 - val_accuracy: 0.7236\n",
            "Epoch 504/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4734 - accuracy: 0.7637 - val_loss: 0.5229 - val_accuracy: 0.7236\n",
            "Epoch 505/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4732 - accuracy: 0.7617 - val_loss: 0.5228 - val_accuracy: 0.7236\n",
            "Epoch 506/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4737 - accuracy: 0.7617 - val_loss: 0.5227 - val_accuracy: 0.7236\n",
            "Epoch 507/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4734 - accuracy: 0.7597 - val_loss: 0.5229 - val_accuracy: 0.7398\n",
            "Epoch 508/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4729 - accuracy: 0.7597 - val_loss: 0.5231 - val_accuracy: 0.7317\n",
            "Epoch 509/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4732 - accuracy: 0.7658 - val_loss: 0.5228 - val_accuracy: 0.7398\n",
            "Epoch 510/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4725 - accuracy: 0.7597 - val_loss: 0.5231 - val_accuracy: 0.7317\n",
            "Epoch 511/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4727 - accuracy: 0.7678 - val_loss: 0.5233 - val_accuracy: 0.7317\n",
            "Epoch 512/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4730 - accuracy: 0.7739 - val_loss: 0.5231 - val_accuracy: 0.7317\n",
            "Epoch 513/1000\n",
            "491/491 [==============================] - 0s 23us/step - loss: 0.4724 - accuracy: 0.7658 - val_loss: 0.5227 - val_accuracy: 0.7398\n",
            "Epoch 514/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4722 - accuracy: 0.7637 - val_loss: 0.5229 - val_accuracy: 0.7317\n",
            "Epoch 515/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4721 - accuracy: 0.7658 - val_loss: 0.5226 - val_accuracy: 0.7398\n",
            "Epoch 516/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4719 - accuracy: 0.7617 - val_loss: 0.5229 - val_accuracy: 0.7317\n",
            "Epoch 517/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4716 - accuracy: 0.7637 - val_loss: 0.5228 - val_accuracy: 0.7317\n",
            "Epoch 518/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4717 - accuracy: 0.7658 - val_loss: 0.5228 - val_accuracy: 0.7317\n",
            "Epoch 519/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4719 - accuracy: 0.7678 - val_loss: 0.5225 - val_accuracy: 0.7317\n",
            "Epoch 520/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4724 - accuracy: 0.7617 - val_loss: 0.5227 - val_accuracy: 0.7317\n",
            "Epoch 521/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4717 - accuracy: 0.7699 - val_loss: 0.5226 - val_accuracy: 0.7398\n",
            "Epoch 522/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4714 - accuracy: 0.7658 - val_loss: 0.5224 - val_accuracy: 0.7236\n",
            "Epoch 523/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4714 - accuracy: 0.7658 - val_loss: 0.5226 - val_accuracy: 0.7398\n",
            "Epoch 524/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4717 - accuracy: 0.7719 - val_loss: 0.5226 - val_accuracy: 0.7398\n",
            "Epoch 525/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4714 - accuracy: 0.7658 - val_loss: 0.5225 - val_accuracy: 0.7398\n",
            "Epoch 526/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4711 - accuracy: 0.7678 - val_loss: 0.5228 - val_accuracy: 0.7317\n",
            "Epoch 527/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4709 - accuracy: 0.7658 - val_loss: 0.5227 - val_accuracy: 0.7317\n",
            "Epoch 528/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4716 - accuracy: 0.7719 - val_loss: 0.5224 - val_accuracy: 0.7398\n",
            "Epoch 529/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4708 - accuracy: 0.7637 - val_loss: 0.5224 - val_accuracy: 0.7398\n",
            "Epoch 530/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4709 - accuracy: 0.7658 - val_loss: 0.5223 - val_accuracy: 0.7317\n",
            "Epoch 531/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4709 - accuracy: 0.7637 - val_loss: 0.5226 - val_accuracy: 0.7317\n",
            "Epoch 532/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4707 - accuracy: 0.7699 - val_loss: 0.5224 - val_accuracy: 0.7398\n",
            "Epoch 533/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4702 - accuracy: 0.7699 - val_loss: 0.5224 - val_accuracy: 0.7398\n",
            "Epoch 534/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4701 - accuracy: 0.7699 - val_loss: 0.5228 - val_accuracy: 0.7317\n",
            "Epoch 535/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4701 - accuracy: 0.7760 - val_loss: 0.5222 - val_accuracy: 0.7398\n",
            "Epoch 536/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4703 - accuracy: 0.7719 - val_loss: 0.5221 - val_accuracy: 0.7317\n",
            "Epoch 537/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4701 - accuracy: 0.7617 - val_loss: 0.5221 - val_accuracy: 0.7317\n",
            "Epoch 538/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4701 - accuracy: 0.7658 - val_loss: 0.5223 - val_accuracy: 0.7398\n",
            "Epoch 539/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4695 - accuracy: 0.7678 - val_loss: 0.5221 - val_accuracy: 0.7317\n",
            "Epoch 540/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4700 - accuracy: 0.7658 - val_loss: 0.5221 - val_accuracy: 0.7398\n",
            "Epoch 541/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4696 - accuracy: 0.7678 - val_loss: 0.5220 - val_accuracy: 0.7317\n",
            "Epoch 542/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4693 - accuracy: 0.7658 - val_loss: 0.5220 - val_accuracy: 0.7317\n",
            "Epoch 543/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4695 - accuracy: 0.7699 - val_loss: 0.5221 - val_accuracy: 0.7398\n",
            "Epoch 544/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4687 - accuracy: 0.7678 - val_loss: 0.5224 - val_accuracy: 0.7317\n",
            "Epoch 545/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4692 - accuracy: 0.7658 - val_loss: 0.5221 - val_accuracy: 0.7398\n",
            "Epoch 546/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4688 - accuracy: 0.7658 - val_loss: 0.5221 - val_accuracy: 0.7398\n",
            "Epoch 547/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4692 - accuracy: 0.7678 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 548/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4692 - accuracy: 0.7678 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 549/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4685 - accuracy: 0.7617 - val_loss: 0.5220 - val_accuracy: 0.7317\n",
            "Epoch 550/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4687 - accuracy: 0.7678 - val_loss: 0.5219 - val_accuracy: 0.7317\n",
            "Epoch 551/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4682 - accuracy: 0.7658 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 552/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4689 - accuracy: 0.7637 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 553/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4681 - accuracy: 0.7637 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 554/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4686 - accuracy: 0.7658 - val_loss: 0.5221 - val_accuracy: 0.7398\n",
            "Epoch 555/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4683 - accuracy: 0.7719 - val_loss: 0.5221 - val_accuracy: 0.7398\n",
            "Epoch 556/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4678 - accuracy: 0.7678 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 557/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4679 - accuracy: 0.7699 - val_loss: 0.5220 - val_accuracy: 0.7317\n",
            "Epoch 558/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4678 - accuracy: 0.7678 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 559/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4678 - accuracy: 0.7678 - val_loss: 0.5221 - val_accuracy: 0.7398\n",
            "Epoch 560/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4673 - accuracy: 0.7637 - val_loss: 0.5222 - val_accuracy: 0.7317\n",
            "Epoch 561/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4675 - accuracy: 0.7678 - val_loss: 0.5222 - val_accuracy: 0.7317\n",
            "Epoch 562/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4675 - accuracy: 0.7637 - val_loss: 0.5221 - val_accuracy: 0.7398\n",
            "Epoch 563/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4674 - accuracy: 0.7678 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 564/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4671 - accuracy: 0.7678 - val_loss: 0.5221 - val_accuracy: 0.7398\n",
            "Epoch 565/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4677 - accuracy: 0.7658 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 566/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4667 - accuracy: 0.7637 - val_loss: 0.5221 - val_accuracy: 0.7398\n",
            "Epoch 567/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4669 - accuracy: 0.7637 - val_loss: 0.5219 - val_accuracy: 0.7480\n",
            "Epoch 568/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4666 - accuracy: 0.7637 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 569/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4669 - accuracy: 0.7637 - val_loss: 0.5222 - val_accuracy: 0.7317\n",
            "Epoch 570/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4666 - accuracy: 0.7637 - val_loss: 0.5223 - val_accuracy: 0.7317\n",
            "Epoch 571/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4665 - accuracy: 0.7760 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 572/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4664 - accuracy: 0.7637 - val_loss: 0.5219 - val_accuracy: 0.7480\n",
            "Epoch 573/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4663 - accuracy: 0.7658 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 574/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4665 - accuracy: 0.7678 - val_loss: 0.5219 - val_accuracy: 0.7480\n",
            "Epoch 575/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4659 - accuracy: 0.7658 - val_loss: 0.5221 - val_accuracy: 0.7317\n",
            "Epoch 576/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4663 - accuracy: 0.7739 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 577/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4662 - accuracy: 0.7637 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 578/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4660 - accuracy: 0.7658 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 579/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4661 - accuracy: 0.7699 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 580/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4658 - accuracy: 0.7617 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 581/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4663 - accuracy: 0.7719 - val_loss: 0.5223 - val_accuracy: 0.7317\n",
            "Epoch 582/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4657 - accuracy: 0.7678 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 583/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4653 - accuracy: 0.7678 - val_loss: 0.5221 - val_accuracy: 0.7317\n",
            "Epoch 584/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4656 - accuracy: 0.7699 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 585/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4659 - accuracy: 0.7678 - val_loss: 0.5220 - val_accuracy: 0.7480\n",
            "Epoch 586/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4657 - accuracy: 0.7617 - val_loss: 0.5221 - val_accuracy: 0.7317\n",
            "Epoch 587/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4657 - accuracy: 0.7658 - val_loss: 0.5222 - val_accuracy: 0.7317\n",
            "Epoch 588/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4650 - accuracy: 0.7658 - val_loss: 0.5219 - val_accuracy: 0.7480\n",
            "Epoch 589/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4655 - accuracy: 0.7658 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 590/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4652 - accuracy: 0.7699 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 591/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4651 - accuracy: 0.7658 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 592/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4650 - accuracy: 0.7678 - val_loss: 0.5220 - val_accuracy: 0.7480\n",
            "Epoch 593/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4648 - accuracy: 0.7637 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 594/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4647 - accuracy: 0.7678 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 595/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4659 - accuracy: 0.7678 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 596/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4648 - accuracy: 0.7719 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
            "Epoch 597/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4652 - accuracy: 0.7678 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 598/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4650 - accuracy: 0.7637 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 599/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4649 - accuracy: 0.7719 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 600/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4648 - accuracy: 0.7699 - val_loss: 0.5219 - val_accuracy: 0.7480\n",
            "Epoch 601/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4648 - accuracy: 0.7719 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 602/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4640 - accuracy: 0.7699 - val_loss: 0.5219 - val_accuracy: 0.7480\n",
            "Epoch 603/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4644 - accuracy: 0.7699 - val_loss: 0.5219 - val_accuracy: 0.7398\n",
            "Epoch 604/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4645 - accuracy: 0.7678 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 605/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4642 - accuracy: 0.7719 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 606/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4644 - accuracy: 0.7678 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 607/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4637 - accuracy: 0.7678 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 608/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4640 - accuracy: 0.7678 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 609/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4647 - accuracy: 0.7719 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 610/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4634 - accuracy: 0.7678 - val_loss: 0.5219 - val_accuracy: 0.7480\n",
            "Epoch 611/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4637 - accuracy: 0.7719 - val_loss: 0.5221 - val_accuracy: 0.7398\n",
            "Epoch 612/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4634 - accuracy: 0.7800 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 613/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4638 - accuracy: 0.7658 - val_loss: 0.5219 - val_accuracy: 0.7480\n",
            "Epoch 614/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4635 - accuracy: 0.7719 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 615/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4634 - accuracy: 0.7821 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 616/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4639 - accuracy: 0.7658 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 617/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4630 - accuracy: 0.7699 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 618/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 619/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4628 - accuracy: 0.7699 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 620/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4635 - accuracy: 0.7699 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 621/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4627 - accuracy: 0.7678 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 622/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4625 - accuracy: 0.7739 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 623/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4630 - accuracy: 0.7719 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 624/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4625 - accuracy: 0.7678 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 625/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4624 - accuracy: 0.7678 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 626/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4627 - accuracy: 0.7739 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 627/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4633 - accuracy: 0.7719 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 628/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4634 - accuracy: 0.7739 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 629/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4622 - accuracy: 0.7800 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 630/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4622 - accuracy: 0.7719 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 631/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4624 - accuracy: 0.7739 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 632/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4624 - accuracy: 0.7678 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 633/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4621 - accuracy: 0.7739 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 634/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 635/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4620 - accuracy: 0.7699 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 636/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4619 - accuracy: 0.7678 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 637/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4621 - accuracy: 0.7719 - val_loss: 0.5220 - val_accuracy: 0.7398\n",
            "Epoch 638/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4624 - accuracy: 0.7719 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 639/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4622 - accuracy: 0.7719 - val_loss: 0.5222 - val_accuracy: 0.7480\n",
            "Epoch 640/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4621 - accuracy: 0.7739 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 641/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4618 - accuracy: 0.7699 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 642/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4616 - accuracy: 0.7678 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 643/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4638 - accuracy: 0.7678 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 644/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 645/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4611 - accuracy: 0.7699 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 646/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4612 - accuracy: 0.7678 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 647/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 648/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4614 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 649/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4611 - accuracy: 0.7719 - val_loss: 0.5214 - val_accuracy: 0.7398\n",
            "Epoch 650/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4613 - accuracy: 0.7739 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 651/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 652/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4620 - accuracy: 0.7678 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 653/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4616 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 654/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4611 - accuracy: 0.7719 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 655/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4609 - accuracy: 0.7699 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 656/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4612 - accuracy: 0.7719 - val_loss: 0.5213 - val_accuracy: 0.7398\n",
            "Epoch 657/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4610 - accuracy: 0.7719 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 658/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 659/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4606 - accuracy: 0.7699 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 660/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.5213 - val_accuracy: 0.7398\n",
            "Epoch 661/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4603 - accuracy: 0.7719 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 662/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4603 - accuracy: 0.7699 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 663/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4608 - accuracy: 0.7780 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 664/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4616 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 665/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4609 - accuracy: 0.7678 - val_loss: 0.5214 - val_accuracy: 0.7398\n",
            "Epoch 666/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4611 - accuracy: 0.7699 - val_loss: 0.5217 - val_accuracy: 0.7480\n",
            "Epoch 667/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4600 - accuracy: 0.7780 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 668/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4602 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7398\n",
            "Epoch 669/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4599 - accuracy: 0.7719 - val_loss: 0.5213 - val_accuracy: 0.7398\n",
            "Epoch 670/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4598 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 671/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4599 - accuracy: 0.7719 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 672/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4612 - accuracy: 0.7719 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 673/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4606 - accuracy: 0.7719 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 674/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4599 - accuracy: 0.7760 - val_loss: 0.5219 - val_accuracy: 0.7480\n",
            "Epoch 675/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4601 - accuracy: 0.7739 - val_loss: 0.5220 - val_accuracy: 0.7480\n",
            "Epoch 676/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 677/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 678/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4606 - accuracy: 0.7658 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 679/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4597 - accuracy: 0.7739 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 680/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4599 - accuracy: 0.7739 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 681/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4610 - accuracy: 0.7699 - val_loss: 0.5218 - val_accuracy: 0.7480\n",
            "Epoch 682/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4596 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 683/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 684/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4596 - accuracy: 0.7719 - val_loss: 0.5212 - val_accuracy: 0.7561\n",
            "Epoch 685/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4598 - accuracy: 0.7699 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 686/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4597 - accuracy: 0.7699 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 687/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4593 - accuracy: 0.7719 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 688/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 689/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4599 - accuracy: 0.7739 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 690/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4592 - accuracy: 0.7699 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 691/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4592 - accuracy: 0.7699 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 692/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4588 - accuracy: 0.7760 - val_loss: 0.5213 - val_accuracy: 0.7398\n",
            "Epoch 693/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4589 - accuracy: 0.7739 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 694/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4588 - accuracy: 0.7678 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 695/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4586 - accuracy: 0.7719 - val_loss: 0.5212 - val_accuracy: 0.7561\n",
            "Epoch 696/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4591 - accuracy: 0.7719 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 697/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4593 - accuracy: 0.7719 - val_loss: 0.5213 - val_accuracy: 0.7642\n",
            "Epoch 698/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4585 - accuracy: 0.7678 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 699/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4593 - accuracy: 0.7739 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 700/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4596 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 701/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4588 - accuracy: 0.7800 - val_loss: 0.5212 - val_accuracy: 0.7561\n",
            "Epoch 702/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4582 - accuracy: 0.7699 - val_loss: 0.5213 - val_accuracy: 0.7398\n",
            "Epoch 703/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4586 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 704/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4586 - accuracy: 0.7678 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 705/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4586 - accuracy: 0.7699 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 706/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4588 - accuracy: 0.7699 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 707/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4599 - accuracy: 0.7739 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
            "Epoch 708/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4587 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
            "Epoch 709/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4588 - accuracy: 0.7678 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
            "Epoch 710/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4582 - accuracy: 0.7719 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 711/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4586 - accuracy: 0.7739 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
            "Epoch 712/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4584 - accuracy: 0.7719 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 713/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4581 - accuracy: 0.7719 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 714/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4582 - accuracy: 0.7780 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
            "Epoch 715/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4580 - accuracy: 0.7800 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 716/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4577 - accuracy: 0.7699 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 717/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4583 - accuracy: 0.7780 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 718/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4581 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 719/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
            "Epoch 720/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4586 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 721/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4580 - accuracy: 0.7739 - val_loss: 0.5213 - val_accuracy: 0.7398\n",
            "Epoch 722/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4585 - accuracy: 0.7739 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 723/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4582 - accuracy: 0.7699 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 724/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4587 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
            "Epoch 725/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4574 - accuracy: 0.7739 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 726/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4580 - accuracy: 0.7719 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 727/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4576 - accuracy: 0.7739 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 728/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4576 - accuracy: 0.7739 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 729/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4578 - accuracy: 0.7719 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 730/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4588 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 731/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4574 - accuracy: 0.7739 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 732/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4572 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 733/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7642\n",
            "Epoch 734/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4580 - accuracy: 0.7780 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 735/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4575 - accuracy: 0.7699 - val_loss: 0.5212 - val_accuracy: 0.7642\n",
            "Epoch 736/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4572 - accuracy: 0.7739 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 737/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 738/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4566 - accuracy: 0.7739 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 739/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4568 - accuracy: 0.7739 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
            "Epoch 740/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4572 - accuracy: 0.7739 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 741/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4571 - accuracy: 0.7719 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 742/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4569 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
            "Epoch 743/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4568 - accuracy: 0.7678 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 744/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4570 - accuracy: 0.7739 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
            "Epoch 745/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4566 - accuracy: 0.7719 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 746/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4569 - accuracy: 0.7800 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 747/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4567 - accuracy: 0.7719 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 748/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4566 - accuracy: 0.7739 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 749/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4571 - accuracy: 0.7739 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 750/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4570 - accuracy: 0.7719 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 751/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4567 - accuracy: 0.7719 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 752/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4571 - accuracy: 0.7699 - val_loss: 0.5212 - val_accuracy: 0.7561\n",
            "Epoch 753/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4568 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7561\n",
            "Epoch 754/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4567 - accuracy: 0.7719 - val_loss: 0.5212 - val_accuracy: 0.7561\n",
            "Epoch 755/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4566 - accuracy: 0.7699 - val_loss: 0.5212 - val_accuracy: 0.7561\n",
            "Epoch 756/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4571 - accuracy: 0.7699 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 757/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4566 - accuracy: 0.7800 - val_loss: 0.5212 - val_accuracy: 0.7561\n",
            "Epoch 758/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4571 - accuracy: 0.7699 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 759/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4564 - accuracy: 0.7780 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 760/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4563 - accuracy: 0.7780 - val_loss: 0.5214 - val_accuracy: 0.7642\n",
            "Epoch 761/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4564 - accuracy: 0.7780 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 762/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 763/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4563 - accuracy: 0.7739 - val_loss: 0.5217 - val_accuracy: 0.7642\n",
            "Epoch 764/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4575 - accuracy: 0.7699 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 765/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4572 - accuracy: 0.7760 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 766/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4559 - accuracy: 0.7739 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 767/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4565 - accuracy: 0.7780 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 768/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 769/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4560 - accuracy: 0.7780 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 770/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4559 - accuracy: 0.7739 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 771/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 772/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4563 - accuracy: 0.7719 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 773/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4557 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7642\n",
            "Epoch 774/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4557 - accuracy: 0.7719 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 775/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4561 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 776/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4558 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 777/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4557 - accuracy: 0.7739 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 778/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4557 - accuracy: 0.7760 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 779/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 780/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.5214 - val_accuracy: 0.7642\n",
            "Epoch 781/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4559 - accuracy: 0.7739 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 782/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4554 - accuracy: 0.7780 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 783/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 784/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4556 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 785/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4563 - accuracy: 0.7719 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 786/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4555 - accuracy: 0.7821 - val_loss: 0.5214 - val_accuracy: 0.7642\n",
            "Epoch 787/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4551 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 788/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4555 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 789/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4552 - accuracy: 0.7739 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 790/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4560 - accuracy: 0.7739 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 791/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4563 - accuracy: 0.7719 - val_loss: 0.5216 - val_accuracy: 0.7642\n",
            "Epoch 792/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4551 - accuracy: 0.7739 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 793/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4562 - accuracy: 0.7800 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 794/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4553 - accuracy: 0.7739 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 795/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.5223 - val_accuracy: 0.7480\n",
            "Epoch 796/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4565 - accuracy: 0.7760 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 797/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4552 - accuracy: 0.7678 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
            "Epoch 798/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4557 - accuracy: 0.7800 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
            "Epoch 799/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4550 - accuracy: 0.7739 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
            "Epoch 800/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4549 - accuracy: 0.7739 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
            "Epoch 801/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4555 - accuracy: 0.7699 - val_loss: 0.5217 - val_accuracy: 0.7561\n",
            "Epoch 802/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
            "Epoch 803/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4546 - accuracy: 0.7760 - val_loss: 0.5217 - val_accuracy: 0.7561\n",
            "Epoch 804/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4552 - accuracy: 0.7800 - val_loss: 0.5217 - val_accuracy: 0.7561\n",
            "Epoch 805/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4550 - accuracy: 0.7780 - val_loss: 0.5218 - val_accuracy: 0.7561\n",
            "Epoch 806/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4548 - accuracy: 0.7719 - val_loss: 0.5217 - val_accuracy: 0.7561\n",
            "Epoch 807/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4546 - accuracy: 0.7699 - val_loss: 0.5217 - val_accuracy: 0.7561\n",
            "Epoch 808/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4545 - accuracy: 0.7800 - val_loss: 0.5217 - val_accuracy: 0.7561\n",
            "Epoch 809/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4550 - accuracy: 0.7719 - val_loss: 0.5218 - val_accuracy: 0.7642\n",
            "Epoch 810/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4555 - accuracy: 0.7719 - val_loss: 0.5217 - val_accuracy: 0.7561\n",
            "Epoch 811/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4545 - accuracy: 0.7719 - val_loss: 0.5217 - val_accuracy: 0.7561\n",
            "Epoch 812/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4547 - accuracy: 0.7699 - val_loss: 0.5218 - val_accuracy: 0.7642\n",
            "Epoch 813/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4552 - accuracy: 0.7719 - val_loss: 0.5218 - val_accuracy: 0.7642\n",
            "Epoch 814/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4545 - accuracy: 0.7780 - val_loss: 0.5218 - val_accuracy: 0.7561\n",
            "Epoch 815/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4546 - accuracy: 0.7760 - val_loss: 0.5218 - val_accuracy: 0.7561\n",
            "Epoch 816/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4544 - accuracy: 0.7739 - val_loss: 0.5219 - val_accuracy: 0.7561\n",
            "Epoch 817/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4546 - accuracy: 0.7739 - val_loss: 0.5218 - val_accuracy: 0.7561\n",
            "Epoch 818/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4556 - accuracy: 0.7719 - val_loss: 0.5219 - val_accuracy: 0.7642\n",
            "Epoch 819/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4547 - accuracy: 0.7699 - val_loss: 0.5219 - val_accuracy: 0.7642\n",
            "Epoch 820/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4542 - accuracy: 0.7760 - val_loss: 0.5220 - val_accuracy: 0.7642\n",
            "Epoch 821/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4545 - accuracy: 0.7719 - val_loss: 0.5220 - val_accuracy: 0.7642\n",
            "Epoch 822/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4541 - accuracy: 0.7739 - val_loss: 0.5219 - val_accuracy: 0.7561\n",
            "Epoch 823/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4545 - accuracy: 0.7760 - val_loss: 0.5218 - val_accuracy: 0.7561\n",
            "Epoch 824/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4550 - accuracy: 0.7719 - val_loss: 0.5219 - val_accuracy: 0.7561\n",
            "Epoch 825/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4541 - accuracy: 0.7760 - val_loss: 0.5220 - val_accuracy: 0.7561\n",
            "Epoch 826/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4551 - accuracy: 0.7699 - val_loss: 0.5219 - val_accuracy: 0.7561\n",
            "Epoch 827/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4545 - accuracy: 0.7760 - val_loss: 0.5220 - val_accuracy: 0.7642\n",
            "Epoch 828/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4540 - accuracy: 0.7780 - val_loss: 0.5219 - val_accuracy: 0.7642\n",
            "Epoch 829/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4539 - accuracy: 0.7760 - val_loss: 0.5219 - val_accuracy: 0.7561\n",
            "Epoch 830/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4542 - accuracy: 0.7719 - val_loss: 0.5218 - val_accuracy: 0.7561\n",
            "Epoch 831/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4549 - accuracy: 0.7719 - val_loss: 0.5220 - val_accuracy: 0.7642\n",
            "Epoch 832/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4546 - accuracy: 0.7800 - val_loss: 0.5220 - val_accuracy: 0.7561\n",
            "Epoch 833/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4541 - accuracy: 0.7760 - val_loss: 0.5219 - val_accuracy: 0.7561\n",
            "Epoch 834/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.5219 - val_accuracy: 0.7561\n",
            "Epoch 835/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4537 - accuracy: 0.7739 - val_loss: 0.5219 - val_accuracy: 0.7561\n",
            "Epoch 836/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4538 - accuracy: 0.7780 - val_loss: 0.5219 - val_accuracy: 0.7561\n",
            "Epoch 837/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4548 - accuracy: 0.7739 - val_loss: 0.5220 - val_accuracy: 0.7561\n",
            "Epoch 838/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4555 - accuracy: 0.7780 - val_loss: 0.5219 - val_accuracy: 0.7561\n",
            "Epoch 839/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4544 - accuracy: 0.7800 - val_loss: 0.5222 - val_accuracy: 0.7561\n",
            "Epoch 840/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4541 - accuracy: 0.7739 - val_loss: 0.5220 - val_accuracy: 0.7561\n",
            "Epoch 841/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4540 - accuracy: 0.7800 - val_loss: 0.5220 - val_accuracy: 0.7561\n",
            "Epoch 842/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.5221 - val_accuracy: 0.7561\n",
            "Epoch 843/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.5220 - val_accuracy: 0.7561\n",
            "Epoch 844/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4535 - accuracy: 0.7780 - val_loss: 0.5220 - val_accuracy: 0.7561\n",
            "Epoch 845/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4539 - accuracy: 0.7780 - val_loss: 0.5220 - val_accuracy: 0.7561\n",
            "Epoch 846/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4543 - accuracy: 0.7760 - val_loss: 0.5221 - val_accuracy: 0.7642\n",
            "Epoch 847/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4543 - accuracy: 0.7760 - val_loss: 0.5224 - val_accuracy: 0.7642\n",
            "Epoch 848/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4538 - accuracy: 0.7780 - val_loss: 0.5221 - val_accuracy: 0.7642\n",
            "Epoch 849/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4535 - accuracy: 0.7780 - val_loss: 0.5221 - val_accuracy: 0.7642\n",
            "Epoch 850/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4537 - accuracy: 0.7739 - val_loss: 0.5226 - val_accuracy: 0.7561\n",
            "Epoch 851/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4542 - accuracy: 0.7821 - val_loss: 0.5222 - val_accuracy: 0.7561\n",
            "Epoch 852/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4539 - accuracy: 0.7739 - val_loss: 0.5223 - val_accuracy: 0.7642\n",
            "Epoch 853/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4536 - accuracy: 0.7760 - val_loss: 0.5221 - val_accuracy: 0.7642\n",
            "Epoch 854/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4538 - accuracy: 0.7800 - val_loss: 0.5221 - val_accuracy: 0.7561\n",
            "Epoch 855/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4540 - accuracy: 0.7739 - val_loss: 0.5225 - val_accuracy: 0.7642\n",
            "Epoch 856/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4535 - accuracy: 0.7800 - val_loss: 0.5221 - val_accuracy: 0.7561\n",
            "Epoch 857/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4540 - accuracy: 0.7739 - val_loss: 0.5222 - val_accuracy: 0.7561\n",
            "Epoch 858/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4535 - accuracy: 0.7739 - val_loss: 0.5222 - val_accuracy: 0.7642\n",
            "Epoch 859/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4559 - accuracy: 0.7699 - val_loss: 0.5222 - val_accuracy: 0.7642\n",
            "Epoch 860/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4536 - accuracy: 0.7739 - val_loss: 0.5223 - val_accuracy: 0.7561\n",
            "Epoch 861/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4534 - accuracy: 0.7739 - val_loss: 0.5222 - val_accuracy: 0.7561\n",
            "Epoch 862/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4530 - accuracy: 0.7739 - val_loss: 0.5223 - val_accuracy: 0.7642\n",
            "Epoch 863/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4538 - accuracy: 0.7780 - val_loss: 0.5222 - val_accuracy: 0.7642\n",
            "Epoch 864/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4535 - accuracy: 0.7800 - val_loss: 0.5224 - val_accuracy: 0.7561\n",
            "Epoch 865/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4537 - accuracy: 0.7760 - val_loss: 0.5223 - val_accuracy: 0.7642\n",
            "Epoch 866/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4532 - accuracy: 0.7780 - val_loss: 0.5223 - val_accuracy: 0.7561\n",
            "Epoch 867/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4532 - accuracy: 0.7739 - val_loss: 0.5224 - val_accuracy: 0.7642\n",
            "Epoch 868/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4534 - accuracy: 0.7760 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 869/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4533 - accuracy: 0.7760 - val_loss: 0.5222 - val_accuracy: 0.7642\n",
            "Epoch 870/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4526 - accuracy: 0.7800 - val_loss: 0.5222 - val_accuracy: 0.7561\n",
            "Epoch 871/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4531 - accuracy: 0.7800 - val_loss: 0.5224 - val_accuracy: 0.7561\n",
            "Epoch 872/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4528 - accuracy: 0.7780 - val_loss: 0.5224 - val_accuracy: 0.7642\n",
            "Epoch 873/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4540 - accuracy: 0.7800 - val_loss: 0.5223 - val_accuracy: 0.7642\n",
            "Epoch 874/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4529 - accuracy: 0.7719 - val_loss: 0.5223 - val_accuracy: 0.7642\n",
            "Epoch 875/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4531 - accuracy: 0.7780 - val_loss: 0.5225 - val_accuracy: 0.7561\n",
            "Epoch 876/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4533 - accuracy: 0.7841 - val_loss: 0.5224 - val_accuracy: 0.7642\n",
            "Epoch 877/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4540 - accuracy: 0.7800 - val_loss: 0.5224 - val_accuracy: 0.7642\n",
            "Epoch 878/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4533 - accuracy: 0.7760 - val_loss: 0.5224 - val_accuracy: 0.7642\n",
            "Epoch 879/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4528 - accuracy: 0.7800 - val_loss: 0.5224 - val_accuracy: 0.7561\n",
            "Epoch 880/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4528 - accuracy: 0.7760 - val_loss: 0.5224 - val_accuracy: 0.7561\n",
            "Epoch 881/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4535 - accuracy: 0.7841 - val_loss: 0.5224 - val_accuracy: 0.7642\n",
            "Epoch 882/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4525 - accuracy: 0.7760 - val_loss: 0.5224 - val_accuracy: 0.7642\n",
            "Epoch 883/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4526 - accuracy: 0.7821 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 884/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4535 - accuracy: 0.7800 - val_loss: 0.5224 - val_accuracy: 0.7642\n",
            "Epoch 885/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4528 - accuracy: 0.7780 - val_loss: 0.5225 - val_accuracy: 0.7642\n",
            "Epoch 886/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4530 - accuracy: 0.7821 - val_loss: 0.5224 - val_accuracy: 0.7642\n",
            "Epoch 887/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4528 - accuracy: 0.7800 - val_loss: 0.5225 - val_accuracy: 0.7561\n",
            "Epoch 888/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4530 - accuracy: 0.7739 - val_loss: 0.5225 - val_accuracy: 0.7642\n",
            "Epoch 889/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4525 - accuracy: 0.7821 - val_loss: 0.5225 - val_accuracy: 0.7642\n",
            "Epoch 890/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4532 - accuracy: 0.7800 - val_loss: 0.5226 - val_accuracy: 0.7561\n",
            "Epoch 891/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4533 - accuracy: 0.7821 - val_loss: 0.5226 - val_accuracy: 0.7642\n",
            "Epoch 892/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4524 - accuracy: 0.7780 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 893/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4524 - accuracy: 0.7760 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 894/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4527 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 895/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4528 - accuracy: 0.7760 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 896/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4525 - accuracy: 0.7800 - val_loss: 0.5226 - val_accuracy: 0.7561\n",
            "Epoch 897/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4533 - accuracy: 0.7841 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
            "Epoch 898/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4529 - accuracy: 0.7760 - val_loss: 0.5225 - val_accuracy: 0.7642\n",
            "Epoch 899/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4527 - accuracy: 0.7780 - val_loss: 0.5225 - val_accuracy: 0.7642\n",
            "Epoch 900/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4525 - accuracy: 0.7821 - val_loss: 0.5226 - val_accuracy: 0.7561\n",
            "Epoch 901/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4525 - accuracy: 0.7821 - val_loss: 0.5226 - val_accuracy: 0.7561\n",
            "Epoch 902/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4526 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 903/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4524 - accuracy: 0.7780 - val_loss: 0.5226 - val_accuracy: 0.7642\n",
            "Epoch 904/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4525 - accuracy: 0.7821 - val_loss: 0.5226 - val_accuracy: 0.7642\n",
            "Epoch 905/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4524 - accuracy: 0.7780 - val_loss: 0.5226 - val_accuracy: 0.7642\n",
            "Epoch 906/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4530 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 907/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4532 - accuracy: 0.7800 - val_loss: 0.5226 - val_accuracy: 0.7561\n",
            "Epoch 908/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4526 - accuracy: 0.7821 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
            "Epoch 909/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4524 - accuracy: 0.7739 - val_loss: 0.5230 - val_accuracy: 0.7642\n",
            "Epoch 910/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4529 - accuracy: 0.7821 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 911/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4520 - accuracy: 0.7800 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
            "Epoch 912/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4523 - accuracy: 0.7760 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 913/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4531 - accuracy: 0.7780 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 914/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4521 - accuracy: 0.7821 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 915/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4520 - accuracy: 0.7760 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 916/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4519 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 917/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4529 - accuracy: 0.7760 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
            "Epoch 918/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4519 - accuracy: 0.7780 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 919/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4530 - accuracy: 0.7821 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
            "Epoch 920/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4530 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 921/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4518 - accuracy: 0.7821 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 922/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4530 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 923/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4519 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 924/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4522 - accuracy: 0.7841 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 925/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4520 - accuracy: 0.7821 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 926/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4530 - accuracy: 0.7841 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
            "Epoch 927/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4515 - accuracy: 0.7862 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
            "Epoch 928/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4515 - accuracy: 0.7760 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 929/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4514 - accuracy: 0.7821 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
            "Epoch 930/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4523 - accuracy: 0.7719 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 931/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4523 - accuracy: 0.7780 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 932/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4516 - accuracy: 0.7821 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 933/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4517 - accuracy: 0.7780 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 934/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4517 - accuracy: 0.7800 - val_loss: 0.5229 - val_accuracy: 0.7642\n",
            "Epoch 935/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4518 - accuracy: 0.7780 - val_loss: 0.5230 - val_accuracy: 0.7561\n",
            "Epoch 936/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4518 - accuracy: 0.7841 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 937/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4521 - accuracy: 0.7841 - val_loss: 0.5230 - val_accuracy: 0.7642\n",
            "Epoch 938/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4516 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 939/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4515 - accuracy: 0.7821 - val_loss: 0.5229 - val_accuracy: 0.7642\n",
            "Epoch 940/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4520 - accuracy: 0.7841 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 941/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4517 - accuracy: 0.7800 - val_loss: 0.5229 - val_accuracy: 0.7642\n",
            "Epoch 942/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4512 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 943/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4511 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 944/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4511 - accuracy: 0.7862 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 945/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4513 - accuracy: 0.7862 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 946/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4513 - accuracy: 0.7821 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 947/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 948/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4516 - accuracy: 0.7821 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 949/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4515 - accuracy: 0.7862 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 950/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4519 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 951/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4514 - accuracy: 0.7780 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 952/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4515 - accuracy: 0.7841 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 953/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4510 - accuracy: 0.7862 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 954/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4518 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 955/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4518 - accuracy: 0.7841 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 956/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4513 - accuracy: 0.7780 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 957/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4511 - accuracy: 0.7862 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 958/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4519 - accuracy: 0.7841 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 959/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4509 - accuracy: 0.7902 - val_loss: 0.5232 - val_accuracy: 0.7561\n",
            "Epoch 960/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4508 - accuracy: 0.7862 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 961/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.4517 - accuracy: 0.7841 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 962/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4528 - accuracy: 0.7719 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 963/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4516 - accuracy: 0.7821 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 964/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4506 - accuracy: 0.7821 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 965/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 966/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4512 - accuracy: 0.7862 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 967/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4516 - accuracy: 0.7902 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 968/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4526 - accuracy: 0.7862 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 969/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4503 - accuracy: 0.7841 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 970/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4510 - accuracy: 0.7821 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 971/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4506 - accuracy: 0.7800 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 972/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4511 - accuracy: 0.7821 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 973/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4507 - accuracy: 0.7780 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 974/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4509 - accuracy: 0.7821 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 975/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4510 - accuracy: 0.7800 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 976/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4517 - accuracy: 0.7780 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 977/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4504 - accuracy: 0.7841 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 978/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4514 - accuracy: 0.7841 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 979/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4506 - accuracy: 0.7821 - val_loss: 0.5229 - val_accuracy: 0.7561\n",
            "Epoch 980/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4516 - accuracy: 0.7862 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 981/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4507 - accuracy: 0.7841 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 982/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4508 - accuracy: 0.7821 - val_loss: 0.5230 - val_accuracy: 0.7561\n",
            "Epoch 983/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4501 - accuracy: 0.7862 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
            "Epoch 984/1000\n",
            "491/491 [==============================] - 0s 24us/step - loss: 0.4502 - accuracy: 0.7821 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 985/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4508 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7642\n",
            "Epoch 986/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4511 - accuracy: 0.7841 - val_loss: 0.5230 - val_accuracy: 0.7561\n",
            "Epoch 987/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4502 - accuracy: 0.7821 - val_loss: 0.5230 - val_accuracy: 0.7642\n",
            "Epoch 988/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4501 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
            "Epoch 989/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
            "Epoch 990/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4504 - accuracy: 0.7862 - val_loss: 0.5228 - val_accuracy: 0.7561\n",
            "Epoch 991/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4502 - accuracy: 0.7800 - val_loss: 0.5234 - val_accuracy: 0.7561\n",
            "Epoch 992/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4502 - accuracy: 0.7841 - val_loss: 0.5229 - val_accuracy: 0.7642\n",
            "Epoch 993/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4499 - accuracy: 0.7841 - val_loss: 0.5229 - val_accuracy: 0.7642\n",
            "Epoch 994/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4500 - accuracy: 0.7862 - val_loss: 0.5230 - val_accuracy: 0.7642\n",
            "Epoch 995/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4505 - accuracy: 0.7862 - val_loss: 0.5229 - val_accuracy: 0.7642\n",
            "Epoch 996/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4503 - accuracy: 0.7841 - val_loss: 0.5230 - val_accuracy: 0.7642\n",
            "Epoch 997/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4505 - accuracy: 0.7821 - val_loss: 0.5232 - val_accuracy: 0.7561\n",
            "Epoch 998/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4504 - accuracy: 0.7841 - val_loss: 0.5232 - val_accuracy: 0.7561\n",
            "Epoch 999/1000\n",
            "491/491 [==============================] - 0s 25us/step - loss: 0.4505 - accuracy: 0.7800 - val_loss: 0.5231 - val_accuracy: 0.7642\n",
            "Epoch 1000/1000\n",
            "491/491 [==============================] - 0s 26us/step - loss: 0.4507 - accuracy: 0.7841 - val_loss: 0.5230 - val_accuracy: 0.7561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n_HCANVksuT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "bd9ba1e3-28c5-451f-af70-07eabc48a6a8"
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Val'], loc = 'upper right')\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE-A5kFIlwS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "9a6a271f-08ec-419b-ce83-985c01f9401b"
      },
      "source": [
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Val'], loc = 'lower right')\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE5RXkRzmwEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "d1936c45-93c0-42c5-9fe8-684001b944f0"
      },
      "source": [
        "#make a prediction\n",
        "prediction = model.predict(X_test)\n",
        "prediction = [1 if y >= 0.5 else 0 for y in prediction]\n",
        "print(prediction)\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
            "[0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOEXnaRnnjfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9e278f47-09a3-4f8f-b85a-e8776370ff9f"
      },
      "source": [
        "#evaluate the model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "pred = model.predict(X_train)\n",
        "pred = [1 if y >= 0.5 else 0 for y in pred]\n",
        "print(classification_report(y_train, pred))\n",
        "print('confusion_matrix: \\n', confusion_matrix(y_train,pred))\n",
        "print('Accuracy: ', accuracy_score(y_train,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.88      0.84       398\n",
            "         1.0       0.73      0.60      0.66       216\n",
            "\n",
            "    accuracy                           0.78       614\n",
            "   macro avg       0.76      0.74      0.75       614\n",
            "weighted avg       0.78      0.78      0.77       614\n",
            "\n",
            "confusion_matrix: \n",
            " [[349  49]\n",
            " [ 86 130]]\n",
            "Accuracy:  0.7801302931596091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08ZJCiICoj2y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b4ab2b41-49e0-426a-868c-681e7ad49f8d"
      },
      "source": [
        "#evaluate the model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "pred = model.predict(X_test)\n",
        "pred = [1 if y >= 0.5 else 0 for y in pred]\n",
        "print(classification_report(y_test, pred))\n",
        "print('confusion_matrix: \\n', confusion_matrix(y_test,pred))\n",
        "print('Accuracy: ', accuracy_score(y_test,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.83      0.83       102\n",
            "         1.0       0.67      0.67      0.67        52\n",
            "\n",
            "    accuracy                           0.78       154\n",
            "   macro avg       0.75      0.75      0.75       154\n",
            "weighted avg       0.78      0.78      0.78       154\n",
            "\n",
            "confusion_matrix: \n",
            " [[85 17]\n",
            " [17 35]]\n",
            "Accuracy:  0.7792207792207793\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}